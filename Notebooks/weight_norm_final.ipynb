{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c77827-0d79-4b61-9d10-0d0e1ab55c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5c77827-0d79-4b61-9d10-0d0e1ab55c3e",
    "outputId": "8b07436c-bd25-4ec7-ebee-c855f1516921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Num GPUs Available:  2\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "#%pip install keras-tcn --no-dependencies\n",
    "\n",
    "#%pip install tensorflow-addons[tensorflow-gpu] --no-dependencies\n",
    "\n",
    "#%pip install pandas --upgrade\n",
    "\n",
    "#%pip install import multivariate_cwru\n",
    "\n",
    "\n",
    "tf.config.list_physical_devices(device_type=None)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "print(visible_devices)\n",
    "num_GPU = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "if num_GPU == 1:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "elif num_GPU == 2:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "elif num_GPU == 4:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "print(\"Num GPUs Available: \", num_GPU)\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "# Data science libraries\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#Deep Learning pkgs\n",
    "from tensorflow.keras import backend as K, Input, Model, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import tensorflow.keras.metrics\n",
    "from tensorflow.keras.metrics import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.activations import swish\n",
    "K.backend()\n",
    "\n",
    "# Python\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "#Project Specific\n",
    "import tcn_ed\n",
    "from tcn_ed import TCN, tcn_full_summary, compiled_tcn\n",
    "import help_matt_val\n",
    "from help_matt_val import predict_batch, create_predict_frames#, create_data_batch, create_frames, sig_divide, matfile_to_df,  create_data_batch_notest, create_frames_notest\n",
    "from help_pre import create_data_batcht as Create_Batch, create_pred_batch\n",
    "import multivariate_cwru"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32ea303d-2a20-423e-a7c7-b5d1a7a4c0eb",
   "metadata": {
    "id": "3NP8ruU8ENeQ"
   },
   "source": [
    "data1 = multivariate_cwru.CWRU(\"12DriveEndFault\", 1000000, 1, 1,2,'1797',\"1797\",\"1772\",\"1750\",\"1730\",normal_condition = True)\n",
    "data2 = multivariate_cwru.CWRU(\"12FanEndFault\", 2400, 1, 1,2,'1797',\"1797\",\"1772\",\"1750\",\"1730\",normal_condition = True)\n",
    "data3 = multivariate_cwru.CWRU(\"48DriveEndFault\", 1000000, 1, 1,2,\"1797\",normal_condition = True)\n",
    "#data = multivariate_cwru.CWRU(\"48DriveEndFault\", 2400, 0, 1,2,\"1772\",normal_condition = True) # Throws an error\n",
    "data4 = multivariate_cwru.CWRU(\"48DriveEndFault\", 1000000, 1, 1,2,\"1750\",normal_condition = True)\n",
    "data5 = multivariate_cwru.CWRU(\"48DriveEndFault\", 1000000, 1, 1,2,\"1730\",normal_condition = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2Dkdg6KoEVe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2Dkdg6KoEVe6",
    "outputId": "ac70f14a-75d3-42e0-c663-63e8c34310d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/upload_dir'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e01dfb-3302-4081-8311-20afa03e5780",
   "metadata": {
    "id": "87e01dfb-3302-4081-8311-20afa03e5780",
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = Path('.')\n",
    "DATA1_PATH = Path(\"./Datasets\")\n",
    "DATA_PATH = Path(\"./Datasets/CWRU\")\n",
    "save_model_path = working_dir / 'Model' \n",
    "DE_path = DATA_PATH / '12DriveEndFault'\n",
    "DE_path1 = DE_path / '1730'\n",
    "DE_path2 = DE_path / '1750'\n",
    "DE_path3 = DE_path / '1772'\n",
    "DE_path4 = DE_path / '1797'\n",
    "\n",
    "FE_path = DATA_PATH / '12FanEndFault'\n",
    "FE_path1 = FE_path / '1730'\n",
    "FE_path2 = FE_path / '1750'\n",
    "FE_path3 = FE_path / '1772'\n",
    "FE_path4 = FE_path / '1797'\n",
    "\n",
    "DE48_path = DATA_PATH / '48DriveEndFault'\n",
    "DE48_path1 = DE48_path / '1730'\n",
    "DE48_path2 = DE48_path / '1750'\n",
    "DE48_path3 = DE48_path / '1772'\n",
    "DE48_path4 = DE48_path / '1797'\n",
    "\n",
    "Normal_path = DATA_PATH / 'NormalBaseline'\n",
    "Normal_path1 = Normal_path / '1730'\n",
    "Normal_path2 = Normal_path / '1750'\n",
    "Normal_path3 = Normal_path / '1772'\n",
    "Normal_path4 = Normal_path / '1797'\n",
    "\n",
    "Paths = [DE_path1, DE_path2, DE_path3, DE_path4, FE_path1, FE_path2, FE_path3, FE_path4, DE48_path1, DE48_path2,  DE48_path4, Normal_path1, Normal_path2, Normal_path3, Normal_path4]\n",
    "data_path = Paths\n",
    "\n",
    "val_path = DATA1_PATH / 'for_pred'\n",
    "Val_path= [val_path]\n",
    "\n",
    "\n",
    "\n",
    "segment_length = 2400 # The length of the window used to take sub-arrays from each file\n",
    "step_size = 300 # the amount the window moves along the sub-array\n",
    "split_perc = 0.2 # percentage of data to put towards the test set\n",
    "b_size = 1024\n",
    "b_size1 = int(b_size*2)\n",
    "#b_size2 = int(b_size / 4)\n",
    "\n",
    "#step_length = step_size\n",
    "\n",
    "for path in [DATA_PATH, save_model_path]:\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "        \n",
    "data_path = Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999ae05-e01c-42ab-b94b-e60e34df9e0f",
   "metadata": {
    "id": "3999ae05-e01c-42ab-b94b-e60e34df9e0f"
   },
   "source": [
    "```'N':0, 'B':1, 'IR':2, 'OR':3```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860ba9d3-9bb6-4604-bdd5-667b337ae7d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "860ba9d3-9bb6-4604-bdd5-667b337ae7d4",
    "outputId": "ff970372-2a15-46f5-f0d6-ca61a1afcf3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325ed5a0-ea45-41f0-b4ab-65880af67bdc",
   "metadata": {
    "id": "325ed5a0-ea45-41f0-b4ab-65880af67bdc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.3,   \n",
    "                                  patience=4, \n",
    "                                  min_lr=0.000000015,\n",
    "                                  verbose=1, \n",
    "                                  cooldown=5)\n",
    "\n",
    "    ES_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.00001, \n",
    "                                             patience=40, \n",
    "                                             verbose=1, \n",
    "                                             mode='auto', \n",
    "                                             baseline=None, \n",
    "                                             restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "    callback = [reduce_lr, ES_cb]\n",
    "\n",
    "def adjust_dilations(dilations: list):\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        return new_dilations\n",
    "        \n",
    "def pred_accuracy(y_true, y_pred):\n",
    "            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "            # convert dense predictions to labels\n",
    "            y_pred_labels = K.cast(y_pred, K.floatx())\n",
    "            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
    "\n",
    "def create_model(num_feat,\n",
    "                 num_classes,\n",
    "                 filt_num,\n",
    "                 kernel_num,\n",
    "                 stack, dilation,\n",
    "                 lr,\n",
    "                 drop_rate,\n",
    "                 segment_length,\n",
    "                 use_skip,\n",
    "                 opt):\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "\n",
    "        input_layer = Input(shape=(segment_length, num_feat))\n",
    "\n",
    "        def get_opt():\n",
    "            if opt == 'adam':\n",
    "                return optimizers.Adam(lr=lr)\n",
    "            elif opt == 'rmsprop':\n",
    "                return optimizers.RMSprop(lr=lr)\n",
    "            else:\n",
    "                raise Exception('Only Adam and RMSProp are available here')\n",
    "            \n",
    "        x = TCN(nb_filters=filt_num,\n",
    "                kernel_size=kernel_num,\n",
    "                nb_stacks=stack,\n",
    "                dilations=[2 ** i for i in range(dilation)],\n",
    "                padding='causal',\n",
    "                use_skip_connections=use_skip,\n",
    "                dropout_rate=drop_rate,\n",
    "                return_sequences=False,\n",
    "                activation='swish', \n",
    "                kernel_initializer='he_uniform',\n",
    "                use_batch_norm=False,\n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=True,\n",
    "                name='Model')(input_layer)\n",
    "\n",
    "        tcn = TCN(nb_filters=filt_num,\n",
    "                  kernel_size=kernel_num,\n",
    "                  nb_stacks=stack,\n",
    "                  dilations=[2 ** i for i in range(dilation)],\n",
    "                  padding='causal',\n",
    "                  use_skip_connections=use_skip,\n",
    "                  dropout_rate=drop_rate,\n",
    "                  return_sequences=False,\n",
    "                  activation='swish', \n",
    "                  kernel_initializer='he_uniform',\n",
    "                  use_batch_norm=False,\n",
    "                  use_layer_norm=False,\n",
    "                  use_weight_norm=True,\n",
    "                  name='Model')\n",
    "\n",
    "        print('Receptive Field Size: %s' % tcn.receptive_field)\n",
    "\n",
    "\n",
    "\n",
    "        print('x.shape=', x.shape)\n",
    "\n",
    "\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax', dtype='float32')(x)\n",
    "        output_layer = x\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO remove later.\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        model.compile(get_opt(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        print('model.x = {}'.format(input_layer.shape))\n",
    "        print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "        print('Filter Length: %s' % filt_num)\n",
    "        print('Kernel Size: %s' % kernel_num)\n",
    "        print('Dilation: %s' % dilation)\n",
    "        print('Learning Rate: %s' % lr)\n",
    "        print('Dropout Rate: %s' % drop_rate)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_func(train_data,\n",
    "               test_dataset,\n",
    "               Val_dataset,\n",
    "               predict_labels,\n",
    "               segment_length,\n",
    "               runs,\n",
    "               filt_num,\n",
    "               kernel_num,\n",
    "               dilation,\n",
    "               stack,\n",
    "               learn_r,\n",
    "               drop_rate,\n",
    "               Model_num):\n",
    "    \n",
    "    \n",
    "        \n",
    "    time1 = timer()\n",
    "        \n",
    "    working_dir = Path('.')\n",
    "    model_path = working_dir / 'Model' / ('Model_{}_k{}_s{}_di{}_dr{}_L{}'.format(Model_num, kernel_num, stack, dilation, drop_rate, segment_length))\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.3,   \n",
    "                                  patience=4, \n",
    "                                  min_lr=0.000015,\n",
    "                                  verbose=0, \n",
    "                                  cooldown=5)\n",
    "\n",
    "    ES_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.00001, \n",
    "                                             patience=15, \n",
    "                                             verbose=0, \n",
    "                                             mode='auto', \n",
    "                                             baseline=None, \n",
    "                                             restore_best_weights=True)\n",
    "    \n",
    "\n",
    "    # to load best weights model.load_weights(latest)\n",
    "\n",
    "    callback = [reduce_lr, ES_cb]\n",
    "    #seg_length = None\n",
    "    time_out = timer()-time1\n",
    "    print('Time till start of create model %s' % time_out)\n",
    "    time2 = timer()\n",
    "    model = create_model(num_feat=1,\n",
    "                         num_classes=4,\n",
    "                         filt_num=filt_num,\n",
    "                         kernel_num=kernel_num,\n",
    "                         stack=stack,\n",
    "                         dilation=dilation,\n",
    "                         lr=learn_r,\n",
    "                         drop_rate=drop_rate,\n",
    "                         segment_length = segment_length,\n",
    "                         use_skip=True,\n",
    "                         opt='adam')\n",
    "\n",
    "    time3 = timer()\n",
    "    time_out = time3-time2\n",
    "    print('Time to create model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        history = model.fit(train_data,\n",
    "                  epochs=runs,\n",
    "                  verbose=2,\n",
    "                  callbacks=callback,\n",
    "                  validation_data=test_dataset)\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    time_out = timer()-time3\n",
    "    print('Time to fit model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        y_preds = model.predict(Val_dataset,\n",
    "                                       verbose=1,\n",
    "                                       callbacks=callback,\n",
    "                                      )\n",
    "        y_argmax2 = np.argmax(y_preds,axis=1)\n",
    "        predict_labels = np.squeeze(predict_labels[:], axis=1)\n",
    "        #for pred1, pred2, pred3, pred4 in y_pred:\n",
    "        #y_argmax = []\n",
    "        #i=0\n",
    "        perc_score = tf.dtypes.cast((sum(pred_accuracy(predict_labels, y_argmax2))/(len(predict_labels))), tf.float16)\n",
    "        Accuracy_test = float(perc_score)\n",
    "        print('Prediction Accuracy: %s' % Accuracy_test)\n",
    "        con_mat = metrics.confusion_matrix(predict_labels, y_argmax2)\n",
    "        class_report = metrics.classification_report(predict_labels, y_argmax2, digits=3)\n",
    "        print(con_mat, '\\n\\n')\n",
    "        print(class_report, '\\n\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    d = {'segment length':[segment_length], 'filters': [filt_num], 'kernel size': [kernel_num], 'stacks':[stack], 'dropout': [drop_rate], 'lr': [learn_r], 'dilation': [dilation], 'Training Time': time_out, 'train loss': [history.history['loss'][-1]], 'train acc': [history.history['sparse_categorical_accuracy'][-1]], 'eval acc': [history.history['val_sparse_categorical_accuracy'][-1]], 'Eval Acc': [Accuracy_test],'C1 correct': [con_mat[0][0]], 'C1 as C2':[con_mat[0][1]], 'C1 as C3':[con_mat[0][2]], 'C1 as C4':[con_mat[0][3]],'C2 as C1': [con_mat[1][0]], 'C2 correct':[con_mat[1][1]], 'C2 as C3':[con_mat[1][2]], 'C2 as C4':[con_mat[1][3]],'C3 as C1': [con_mat[2][0]], 'C3 as C2':[con_mat[2][1]], 'C3 correct':[con_mat[2][2]], 'C3 as C4':[con_mat[2][3]],'C4 as C1': [con_mat[3][0]], 'C4 as C2':[con_mat[3][1]], 'C4 as C3':[con_mat[3][2]], 'C4 correct':[con_mat[3][3]]}\n",
    "    \n",
    "    \n",
    "    append_list2_in = pd.DataFrame.from_dict(d)\n",
    "    \n",
    "    time_out = timer()-time1\n",
    "    print('Total Time %s' % time_out)\n",
    "    \n",
    "    return history, y_preds, append_list2_in\n",
    "\n",
    "def create_model2(num_feat,\n",
    "                 num_classes,\n",
    "                 filt_num,\n",
    "                 kernel_num,\n",
    "                 stack, dilation,\n",
    "                 lr,\n",
    "                 drop_rate,\n",
    "                 segment_length,\n",
    "                 use_skip,\n",
    "                 opt):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        #x =Sequential()\n",
    "\n",
    "        \n",
    "        input_layer = Input(shape=(segment_length, num_feat))\n",
    "\n",
    "        def get_opt():\n",
    "            if opt == 'adam':\n",
    "                return optimizers.Adam(lr=lr)\n",
    "            elif opt == 'rmsprop':\n",
    "                return optimizers.RMSprop(lr=lr)\n",
    "            else:\n",
    "                raise Exception('Only Adam and RMSProp are available here')\n",
    "            \n",
    "        x = TCN(nb_filters=filt_num,\n",
    "                kernel_size=kernel_num,\n",
    "                nb_stacks=stack,\n",
    "                dilations=[2 ** i for i in range(dilation)],\n",
    "                padding='causal',\n",
    "                use_skip_connections=use_skip,\n",
    "                dropout_rate=drop_rate,\n",
    "                return_sequences=False,\n",
    "                activation='swish', \n",
    "                kernel_initializer='he_uniform',\n",
    "                use_batch_norm=False,\n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=True,\n",
    "                name='Model')(input_layer)\n",
    "\n",
    "        tcn = TCN(nb_filters=filt_num,\n",
    "                  kernel_size=kernel_num,\n",
    "                  nb_stacks=stack,\n",
    "                  dilations=[2 ** i for i in range(dilation)],\n",
    "                  padding='causal',\n",
    "                  use_skip_connections=use_skip,\n",
    "                  dropout_rate=drop_rate,\n",
    "                  return_sequences=False,\n",
    "                  activation='swish', \n",
    "                  kernel_initializer='he_uniform',\n",
    "                  use_batch_norm=True,\n",
    "                  use_layer_norm=False,\n",
    "                  use_weight_norm=False,\n",
    "                  name='Model')\n",
    "\n",
    "        print('Receptive Field Size: %s' % tcn.receptive_field)\n",
    "\n",
    "\n",
    "\n",
    "        print('x.shape=', x.shape)\n",
    "\n",
    "\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax', dtype='float32')(x)\n",
    "        output_layer = x\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO remove later.\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        model.compile(get_opt(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        print('model.x = {}'.format(input_layer.shape))\n",
    "        print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "        print('Filter Length: %s' % filt_num)\n",
    "        print('Kernel Size: %s' % kernel_num)\n",
    "        print('Dilation: %s' % dilation)\n",
    "        print('Learning Rate: %s' % lr)\n",
    "        print('Dropout Rate: %s' % drop_rate)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_func2(train_data,\n",
    "               test_dataset,\n",
    "               Val_dataset,\n",
    "               predict_labels,\n",
    "               segment_length,\n",
    "               runs,\n",
    "               filt_num,\n",
    "               kernel_num,\n",
    "               dilation,\n",
    "               stack,\n",
    "               learn_r,\n",
    "               drop_rate,\n",
    "               Model_num):\n",
    "    \n",
    "    \n",
    "        \n",
    "    time1 = timer()\n",
    "        \n",
    "    working_dir = Path('.')\n",
    "    model_path = working_dir / 'Model' / ('Model_{}_k{}_s{}_di{}_dr{}_L{}.H5'.format(Model_num, kernel_num, stack, dilation, drop_rate, segment_length))\n",
    "    \n",
    "    \n",
    "\n",
    "    #seg_length = None\n",
    "    time_out = timer()-time1\n",
    "    print('Time till start of create model %s' % time_out)\n",
    "    time2 = timer()\n",
    "    model = create_model(num_feat=1,\n",
    "                         num_classes=4,\n",
    "                         filt_num=filt_num,\n",
    "                         kernel_num=kernel_num,\n",
    "                         stack=stack,\n",
    "                         dilation=dilation,\n",
    "                         lr=learn_r,\n",
    "                         drop_rate=drop_rate,\n",
    "                         segment_length = segment_length,\n",
    "                         use_skip=True,\n",
    "                         opt='adam')\n",
    "\n",
    "    time3 = timer()\n",
    "    time_out = time3-time2\n",
    "    print('Time to create model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        history = model.fit(train_data,\n",
    "                  epochs=runs,\n",
    "                  verbose=2,\n",
    "                  callbacks=callback,\n",
    "                  validation_data=test_dataset)\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    time_out = timer()-time3\n",
    "    print('Time to fit model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        y_preds = model.predict(Val_dataset,\n",
    "                                       verbose=0,\n",
    "                                       callbacks=callback,\n",
    "                                      )\n",
    "        y_argmax2 = np.argmax(y_preds,axis=1)\n",
    "        predict_labels = np.squeeze(predict_labels[:], axis=1)\n",
    "        #for pred1, pred2, pred3, pred4 in y_pred:\n",
    "        #y_argmax = []\n",
    "        #i=0\n",
    "        perc_score = tf.dtypes.cast((sum(pred_accuracy(predict_labels, y_argmax2))/(len(predict_labels))), tf.float16)\n",
    "        Accuracy_test = float(perc_score)\n",
    "        print('Prediction Accuracy: %s' % Accuracy_test)\n",
    "        con_mat = metrics.confusion_matrix(predict_labels, y_argmax2)\n",
    "        class_report = metrics.classification_report(predict_labels, y_argmax2, digits=3)\n",
    "        print(con_mat, '\\n\\n')\n",
    "        print(class_report, '\\n\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    d = {'segment length':[segment_length], 'filters': [filt_num], 'kernel size': [kernel_num], 'stacks':[stack], 'dropout': [drop_rate], 'lr': [learn_r], 'dilation': [dilation], 'Training Time': time_out, 'train loss': [history.history['loss'][-1]], 'train acc': [history.history['sparse_categorical_accuracy'][-1]], 'eval acc': [history.history['val_sparse_categorical_accuracy'][-1]], 'Eval Acc': [Accuracy_test],'C1 correct': [con_mat[0][0]], 'C1 as C2':[con_mat[0][1]], 'C1 as C3':[con_mat[0][2]], 'C1 as C4':[con_mat[0][3]],'C2 as C1': [con_mat[1][0]], 'C2 correct':[con_mat[1][1]], 'C2 as C3':[con_mat[1][2]], 'C2 as C4':[con_mat[1][3]],'C3 as C1': [con_mat[2][0]], 'C3 as C2':[con_mat[2][1]], 'C3 correct':[con_mat[2][2]], 'C3 as C4':[con_mat[2][3]],'C4 as C1': [con_mat[3][0]], 'C4 as C2':[con_mat[3][1]], 'C4 as C3':[con_mat[3][2]], 'C4 correct':[con_mat[3][3]]}\n",
    "    \n",
    "    \n",
    "    append_list2_in = pd.DataFrame.from_dict(d)\n",
    "       \n",
    "    time_out = timer()-time1\n",
    "    print('Total Time %s' % time_out)\n",
    "    \n",
    "    return model, history, y_preds, append_list2_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153bc396-4658-4733-a0da-28538f2399e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "153bc396-4658-4733-a0da-28538f2399e4",
    "outputId": "0718584f-69bc-4f29-fdbb-44d712b98742",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sig Divide Time: 1.458326816558838\n",
      "Sig Divide Time: 8.080130338668823\n"
     ]
    }
   ],
   "source": [
    "b_size = 512 #normally 2048 but 512 on colab\n",
    "b_size2 = int(b_size / 4)\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "waste_split = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94466063-73f4-4f3d-885d-6cb4c2cf1bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sig Divide Time: 1.0959303379058838\n"
     ]
    }
   ],
   "source": [
    "val_dataset, X_v1, predict_labels= create_pred_batch(Val_path=Val_path, segment_length=segment_length, step_length=step_size, b_size=int(b_size/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "GtmdGgBL5qAl",
   "metadata": {
    "id": "GtmdGgBL5qAl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number 2\n",
      "Time till start of create model 0.00011665100009849994\n",
      "Receptive Field Size: 2541\n",
      "x.shape= (None, 16)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "model.x = (None, 2400, 1)\n",
      "model.y = (None, 4)\n",
      "Filter Length: 16\n",
      "Kernel Size: 11\n",
      "Dilation: 7\n",
      "Learning Rate: 0.0125\n",
      "Dropout Rate: 0.3\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2400, 1)]         0         \n",
      "_________________________________________________________________\n",
      "Model (TCN)                  (None, 16)                74286     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 74,354\n",
      "Trainable params: 37,332\n",
      "Non-trainable params: 37,022\n",
      "_________________________________________________________________\n",
      "Time to create model 1.961954508999952\n",
      "Epoch 1/75\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "214/214 - 143s - loss: 0.8714 - sparse_categorical_accuracy: 0.5986 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.7105\n",
      "Epoch 2/75\n",
      "214/214 - 110s - loss: 0.5276 - sparse_categorical_accuracy: 0.7668 - val_loss: 0.5795 - val_sparse_categorical_accuracy: 0.7729\n",
      "Epoch 3/75\n",
      "214/214 - 109s - loss: 0.4207 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.5571 - val_sparse_categorical_accuracy: 0.8115\n",
      "Epoch 4/75\n",
      "214/214 - 110s - loss: 0.3563 - sparse_categorical_accuracy: 0.8528 - val_loss: 0.7912 - val_sparse_categorical_accuracy: 0.8273\n",
      "Epoch 5/75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ba0767cbeb79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mappend_list_time1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Number %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mm_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m history, y_preds, res_list = train_func(train_data=train_dataset,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                         \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                         \u001b[0mVal_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d2cf3b98529d>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(train_data, test_dataset, Val_dataset, predict_labels, segment_length, runs, filt_num, kernel_num, dilation, stack, learn_r, drop_rate, Model_num)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time to create model %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtime_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmirrored_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         history = model.fit(train_data,\n\u001b[0m\u001b[1;32m    183\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Increased Dropout\n",
    "Learning_Rate = 0.0125\n",
    "Drop_rate = 0.3\n",
    "Repeats = 75\n",
    "\n",
    "m_count = 2\n",
    "append_list_time1 = pd.DataFrame\n",
    "print('Model Number %s' % m_count)\n",
    "history, y_preds, res_list = train_func(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=16,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()\n",
    "               "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4c65015-2883-4399-b1c7-c97f3df350c0",
   "metadata": {
    "id": "b4c65015-2883-4399-b1c7-c97f3df350c0",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb548e3-948f-4df7-942f-d90ec7ab68eb",
   "metadata": {
    "id": "3fb548e3-948f-4df7-942f-d90ec7ab68eb"
   },
   "source": [
    "# Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d5748-a3e9-449d-8b54-030e531aa8b1",
   "metadata": {
    "id": "cd4d5748-a3e9-449d-8b54-030e531aa8b1"
   },
   "outputs": [],
   "source": [
    "append_list_time1.sort_values(by=['segment length', 'kernel size', 'stacks', 'dilation', 'filters'], ascending=[True, False, False, False, True])\n",
    "append_list_time1.to_csv(r'{}.csv'.format('List_Check_300'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1570ba-1772-4251-827f-fef44b4e1a50",
   "metadata": {
    "id": "8a1570ba-1772-4251-827f-fef44b4e1a50"
   },
   "outputs": [],
   "source": [
    "append_list_time1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd369cd-6f1f-4962-999f-b2598bebcb3c",
   "metadata": {
    "id": "0fd369cd-6f1f-4962-999f-b2598bebcb3c"
   },
   "source": [
    "# Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f12ce-e8bb-4d13-9cfd-5b9ea08fddf3",
   "metadata": {
    "id": "d94f12ce-e8bb-4d13-9cfd-5b9ea08fddf3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
