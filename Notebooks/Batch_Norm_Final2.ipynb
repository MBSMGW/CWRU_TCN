{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c77827-0d79-4b61-9d10-0d0e1ab55c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5c77827-0d79-4b61-9d10-0d0e1ab55c3e",
    "outputId": "8b07436c-bd25-4ec7-ebee-c855f1516921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:1',)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "#%pip install keras-tcn --no-dependencies\n",
    "\n",
    "#%pip install tensorflow-addons[tensorflow-gpu] --no-dependencies\n",
    "\n",
    "#%pip install pandas --upgrade\n",
    "\n",
    "#%pip install import multivariate_cwru\n",
    "\n",
    "\n",
    "tf.config.list_physical_devices(device_type=None)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "print(visible_devices)\n",
    "num_GPU = len(tf.config.experimental.list_physical_devices('/physical_device:GPU:0'))\n",
    "#if num_GPU == 1:\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#elif num_GPU == 2:\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#elif num_GPU == 4:\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#print(\"Num GPUs Available: \", num_GPU)\n",
    "#tf.debugging.set_log_device_placement(False)\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:1\"])\n",
    "#strategy = tf.distribute.MirroredStrategy(\n",
    "    #cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "# Data science libraries\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#Deep Learning pkgs\n",
    "from tensorflow.keras import backend as K, Input, Model, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import tensorflow.keras.metrics\n",
    "from tensorflow.keras.metrics import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.activations import swish\n",
    "K.backend()\n",
    "\n",
    "# Python\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "#Project Specific\n",
    "import tcn_ed\n",
    "from tcn_ed import TCN, tcn_full_summary, compiled_tcn\n",
    "import help_matt_val\n",
    "from help_matt_val import predict_batch, create_predict_frames#, create_data_batch, create_frames, sig_divide, matfile_to_df,  create_data_batch_notest, create_frames_notest\n",
    "from help_pre import create_data_batcht as Create_Batch, create_pred_batch\n",
    "import multivariate_cwru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860ba9d3-9bb6-4604-bdd5-667b337ae7d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "860ba9d3-9bb6-4604-bdd5-667b337ae7d4",
    "outputId": "ff970372-2a15-46f5-f0d6-ca61a1afcf3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a76b873-ae3c-4cf8-833a-36af7e364536",
   "metadata": {
    "id": "3NP8ruU8ENeQ",
    "tags": []
   },
   "source": [
    "data1 = multivariate_cwru.CWRU(\"12DriveEndFault\", 1000000, 1, 1,2,'1797',\"1797\",\"1772\",\"1750\",\"1730\",normal_condition = True)\n",
    "data2 = multivariate_cwru.CWRU(\"12FanEndFault\", 2400, 1, 1,2,'1797',\"1797\",\"1772\",\"1750\",\"1730\",normal_condition = True)\n",
    "data3 = multivariate_cwru.CWRU(\"48DriveEndFault\", 1000000, 1, 1,2,\"1797\",normal_condition = True)\n",
    "#data = multivariate_cwru.CWRU(\"48DriveEndFault\", 2400, 0, 1,2,\"1772\",normal_condition = True) # Throws an error\n",
    "data4 = multivariate_cwru.CWRU(\"48DriveEndFault\", 1000000, 1, 1,2,\"1750\",normal_condition = True)\n",
    "data5 = multivariate_cwru.CWRU(\"48DriveEndFault\", 1000000, 1, 1,2,\"1730\",normal_condition = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2Dkdg6KoEVe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2Dkdg6KoEVe6",
    "outputId": "ac70f14a-75d3-42e0-c663-63e8c34310d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/upload_dir'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e01dfb-3302-4081-8311-20afa03e5780",
   "metadata": {
    "id": "87e01dfb-3302-4081-8311-20afa03e5780",
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = Path('.')\n",
    "DATA1_PATH = Path(\"./Datasets\")\n",
    "DATA_PATH = Path(\"./Datasets/CWRU\")\n",
    "save_model_path = working_dir / 'Model' \n",
    "DE_path = DATA_PATH / '12DriveEndFault'\n",
    "DE_path1 = DE_path / '1730'\n",
    "DE_path2 = DE_path / '1750'\n",
    "DE_path3 = DE_path / '1772'\n",
    "DE_path4 = DE_path / '1797'\n",
    "\n",
    "FE_path = DATA_PATH / '12FanEndFault'\n",
    "FE_path1 = FE_path / '1730'\n",
    "FE_path2 = FE_path / '1750'\n",
    "FE_path3 = FE_path / '1772'\n",
    "FE_path4 = FE_path / '1797'\n",
    "\n",
    "DE48_path = DATA_PATH / '48DriveEndFault'\n",
    "DE48_path1 = DE48_path / '1730'\n",
    "DE48_path2 = DE48_path / '1750'\n",
    "DE48_path3 = DE48_path / '1772'\n",
    "DE48_path4 = DE48_path / '1797'\n",
    "\n",
    "Normal_path = DATA_PATH / 'NormalBaseline'\n",
    "Normal_path1 = Normal_path / '1730'\n",
    "Normal_path2 = Normal_path / '1750'\n",
    "Normal_path3 = Normal_path / '1772'\n",
    "Normal_path4 = Normal_path / '1797'\n",
    "\n",
    "Paths = [DE_path1, DE_path2, DE_path3, DE_path4, FE_path1, FE_path2, FE_path3, FE_path4, DE48_path1, DE48_path2,  DE48_path4, Normal_path1, Normal_path2, Normal_path3, Normal_path4]\n",
    "data_path = Paths\n",
    "\n",
    "val_path = DATA1_PATH / 'for_pred'\n",
    "Val_path= [val_path]\n",
    "\n",
    "\n",
    "\n",
    "segment_length = 2400 # The length of the window used to take sub-arrays from each file\n",
    "step_size = 300 # the amount the window moves along the sub-array\n",
    "split_perc = 0.2 # percentage of data to put towards the test set\n",
    "b_size = 1024\n",
    "b_size1 = int(b_size*2)\n",
    "#b_size2 = int(b_size / 4)\n",
    "\n",
    "#step_length = step_size\n",
    "\n",
    "for path in [DATA_PATH, save_model_path]:\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "        \n",
    "data_path = Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999ae05-e01c-42ab-b94b-e60e34df9e0f",
   "metadata": {
    "id": "3999ae05-e01c-42ab-b94b-e60e34df9e0f"
   },
   "source": [
    "```'N':0, 'B':1, 'IR':2, 'OR':3```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "325ed5a0-ea45-41f0-b4ab-65880af67bdc",
   "metadata": {
    "id": "325ed5a0-ea45-41f0-b4ab-65880af67bdc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.3,   \n",
    "                                  patience=40, \n",
    "                                  min_lr=0.000000015,\n",
    "                                  verbose=1, \n",
    "                                  cooldown=5)\n",
    "\n",
    "    ES_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.00001, \n",
    "                                             patience=70, \n",
    "                                             verbose=1, \n",
    "                                             mode='auto', \n",
    "                                             baseline=None, \n",
    "                                             restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "    callback = [reduce_lr, ES_cb]\n",
    "\n",
    "def adjust_dilations(dilations: list):\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        return new_dilations\n",
    "        \n",
    "def pred_accuracy(y_true, y_pred):\n",
    "            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "            # convert dense predictions to labels\n",
    "            y_pred_labels = K.cast(y_pred, K.floatx())\n",
    "            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
    "\n",
    "def create_model(num_feat,\n",
    "                 num_classes,\n",
    "                 filt_num,\n",
    "                 kernel_num,\n",
    "                 stack, dilation,\n",
    "                 lr,\n",
    "                 drop_rate,\n",
    "                 segment_length,\n",
    "                 use_skip,\n",
    "                 opt):\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "\n",
    "        input_layer = Input(shape=(segment_length, num_feat))\n",
    "\n",
    "        def get_opt():\n",
    "            if opt == 'adam':\n",
    "                return optimizers.Adam(lr=lr)\n",
    "            elif opt == 'rmsprop':\n",
    "                return optimizers.RMSprop(lr=lr)\n",
    "            else:\n",
    "                raise Exception('Only Adam and RMSProp are available here')\n",
    "            \n",
    "        x = TCN(nb_filters=filt_num,\n",
    "                kernel_size=kernel_num,\n",
    "                nb_stacks=stack,\n",
    "                dilations=[2 ** i for i in range(dilation)],\n",
    "                padding='causal',\n",
    "                use_skip_connections=use_skip,\n",
    "                dropout_rate=drop_rate,\n",
    "                return_sequences=False,\n",
    "                activation='swish', \n",
    "                kernel_initializer='he_uniform',\n",
    "                use_batch_norm=True,\n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=False,\n",
    "                name='Model')(input_layer)\n",
    "\n",
    "        tcn = TCN(nb_filters=filt_num,\n",
    "                  kernel_size=kernel_num,\n",
    "                  nb_stacks=stack,\n",
    "                  dilations=[2 ** i for i in range(dilation)],\n",
    "                  padding='causal',\n",
    "                  use_skip_connections=use_skip,\n",
    "                  dropout_rate=drop_rate,\n",
    "                  return_sequences=False,\n",
    "                  activation='swish', \n",
    "                  kernel_initializer='he_uniform',\n",
    "                  use_batch_norm=True,\n",
    "                  use_layer_norm=False,\n",
    "                  use_weight_norm=False,\n",
    "                  name='Model')\n",
    "\n",
    "        print('Receptive Field Size: %s' % tcn.receptive_field)\n",
    "\n",
    "\n",
    "\n",
    "        print('x.shape=', x.shape)\n",
    "\n",
    "\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax', dtype='float32')(x)\n",
    "        output_layer = x\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO remove later.\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        model.compile(get_opt(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        print('model.x = {}'.format(input_layer.shape))\n",
    "        print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "        print('Filter Length: %s' % filt_num)\n",
    "        print('Kernel Size: %s' % kernel_num)\n",
    "        print('Dilation: %s' % dilation)\n",
    "        print('Learning Rate: %s' % lr)\n",
    "        print('Dropout Rate: %s' % drop_rate)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_func(train_data,\n",
    "               test_dataset,\n",
    "               Val_dataset,\n",
    "               predict_labels,\n",
    "               segment_length,\n",
    "               runs,\n",
    "               filt_num,\n",
    "               kernel_num,\n",
    "               dilation,\n",
    "               stack,\n",
    "               learn_r,\n",
    "               drop_rate,\n",
    "               Model_num):\n",
    "    \n",
    "    \n",
    "        \n",
    "    time1 = timer()\n",
    "        \n",
    "    working_dir = Path('.')\n",
    "    model_path = working_dir / 'Model' / ('Model_{}_k{}_s{}_di{}_dr{}_L{}'.format(Model_num, kernel_num, stack, dilation, drop_rate, segment_length))\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.3,   \n",
    "                                  patience=40, \n",
    "                                  min_lr=0.000015,\n",
    "                                  verbose=0, \n",
    "                                  cooldown=5)\n",
    "\n",
    "    ES_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.00001, \n",
    "                                             patience=70, \n",
    "                                             verbose=0, \n",
    "                                             mode='auto', \n",
    "                                             baseline=None, \n",
    "                                             restore_best_weights=True)\n",
    "    \n",
    "\n",
    "    # to load best weights model.load_weights(latest)\n",
    "\n",
    "    callback = ES_cb# ] [reduce_lr, \n",
    "    #seg_length = None\n",
    "    time_out = timer()-time1\n",
    "    print('Time till start of create model %s' % time_out)\n",
    "    time2 = timer()\n",
    "    model = create_model(num_feat=1,\n",
    "                         num_classes=4,\n",
    "                         filt_num=filt_num,\n",
    "                         kernel_num=kernel_num,\n",
    "                         stack=stack,\n",
    "                         dilation=dilation,\n",
    "                         lr=learn_r,\n",
    "                         drop_rate=drop_rate,\n",
    "                         segment_length = segment_length,\n",
    "                         use_skip=True,\n",
    "                         opt='adam')\n",
    "\n",
    "    time3 = timer()\n",
    "    time_out = time3-time2\n",
    "    print('Time to create model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        history = model.fit(train_data,\n",
    "                  epochs=runs,\n",
    "                  verbose=2,\n",
    "                  callbacks=callback,\n",
    "                  validation_data=test_dataset)\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    time_out = timer()-time3\n",
    "    print('Time to fit model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        y_preds = model.predict(Val_dataset,\n",
    "                                       verbose=1,\n",
    "                                       callbacks=callback,\n",
    "                                      )\n",
    "        y_argmax2 = np.argmax(y_preds,axis=1)\n",
    "        predict_labels = np.squeeze(predict_labels[:], axis=1)\n",
    "        #for pred1, pred2, pred3, pred4 in y_pred:\n",
    "        #y_argmax = []\n",
    "        #i=0\n",
    "        perc_score = tf.dtypes.cast((sum(pred_accuracy(predict_labels, y_argmax2))/(len(predict_labels))), tf.float16)\n",
    "        Accuracy_test = float(perc_score)\n",
    "        print('Prediction Accuracy: %s' % Accuracy_test)\n",
    "        con_mat = metrics.confusion_matrix(predict_labels, y_argmax2)\n",
    "        class_report = metrics.classification_report(predict_labels, y_argmax2, digits=3)\n",
    "        print(con_mat, '\\n\\n')\n",
    "        print(class_report, '\\n\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    d = {'segment length':[segment_length], 'filters': [filt_num], 'kernel size': [kernel_num], 'stacks':[stack], 'dropout': [drop_rate], 'lr': [learn_r], 'dilation': [dilation], 'Training Time': time_out, 'train loss': [history.history['loss'][-1]], 'train acc': [history.history['sparse_categorical_accuracy'][-1]], 'eval acc': [history.history['val_sparse_categorical_accuracy'][-1]], 'Eval Acc': [Accuracy_test],'C1 correct': [con_mat[0][0]], 'C1 as C2':[con_mat[0][1]], 'C1 as C3':[con_mat[0][2]], 'C1 as C4':[con_mat[0][3]],'C2 as C1': [con_mat[1][0]], 'C2 correct':[con_mat[1][1]], 'C2 as C3':[con_mat[1][2]], 'C2 as C4':[con_mat[1][3]],'C3 as C1': [con_mat[2][0]], 'C3 as C2':[con_mat[2][1]], 'C3 correct':[con_mat[2][2]], 'C3 as C4':[con_mat[2][3]],'C4 as C1': [con_mat[3][0]], 'C4 as C2':[con_mat[3][1]], 'C4 as C3':[con_mat[3][2]], 'C4 correct':[con_mat[3][3]]}\n",
    "    \n",
    "    \n",
    "    append_list2_in = pd.DataFrame.from_dict(d)\n",
    "    \n",
    "    time_out = timer()-time1\n",
    "    print('Total Time %s' % time_out)\n",
    "    \n",
    "    return history, y_preds, append_list2_in\n",
    "\n",
    "def create_model2(num_feat,\n",
    "                 num_classes,\n",
    "                 filt_num,\n",
    "                 kernel_num,\n",
    "                 stack, dilation,\n",
    "                 lr,\n",
    "                 drop_rate,\n",
    "                 segment_length,\n",
    "                 use_skip,\n",
    "                 opt):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        #x =Sequential()\n",
    "\n",
    "        \n",
    "        input_layer = Input(shape=(segment_length, num_feat))\n",
    "\n",
    "        def get_opt():\n",
    "            if opt == 'adam':\n",
    "                return optimizers.Adam(lr=lr)\n",
    "            elif opt == 'rmsprop':\n",
    "                return optimizers.RMSprop(lr=lr)\n",
    "            else:\n",
    "                raise Exception('Only Adam and RMSProp are available here')\n",
    "            \n",
    "        x = TCN(nb_filters=filt_num,\n",
    "                kernel_size=kernel_num,\n",
    "                nb_stacks=stack,\n",
    "                dilations=[2 ** i for i in range(dilation)],\n",
    "                padding='causal',\n",
    "                use_skip_connections=use_skip,\n",
    "                dropout_rate=drop_rate,\n",
    "                return_sequences=False,\n",
    "                activation='swish', \n",
    "                kernel_initializer='he_uniform',\n",
    "                use_batch_norm=True,\n",
    "                use_layer_norm=False,\n",
    "                use_weight_norm=False,\n",
    "                name='Model')(input_layer)\n",
    "\n",
    "        tcn = TCN(nb_filters=filt_num,\n",
    "                  kernel_size=kernel_num,\n",
    "                  nb_stacks=stack,\n",
    "                  dilations=[2 ** i for i in range(dilation)],\n",
    "                  padding='causal',\n",
    "                  use_skip_connections=use_skip,\n",
    "                  dropout_rate=drop_rate,\n",
    "                  return_sequences=False,\n",
    "                  activation='swish', \n",
    "                  kernel_initializer='he_uniform',\n",
    "                  use_batch_norm=True,\n",
    "                  use_layer_norm=False,\n",
    "                  use_weight_norm=False,\n",
    "                  name='Model')\n",
    "\n",
    "        print('Receptive Field Size: %s' % tcn.receptive_field)\n",
    "\n",
    "\n",
    "\n",
    "        print('x.shape=', x.shape)\n",
    "\n",
    "\n",
    "        # classification\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax', dtype='float32')(x)\n",
    "        output_layer = x\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # https://github.com/keras-team/keras/pull/11373\n",
    "        # It's now in Keras@master but still not available with pip.\n",
    "        # TODO remove later.\n",
    "\n",
    "    with mirrored_strategy.scope():\n",
    "        model.compile(get_opt(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "        print('model.x = {}'.format(input_layer.shape))\n",
    "        print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "        print('Filter Length: %s' % filt_num)\n",
    "        print('Kernel Size: %s' % kernel_num)\n",
    "        print('Dilation: %s' % dilation)\n",
    "        print('Learning Rate: %s' % lr)\n",
    "        print('Dropout Rate: %s' % drop_rate)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model\n",
    "\n",
    "def train_func2(train_data,\n",
    "               test_dataset,\n",
    "               Val_dataset,\n",
    "               predict_labels,\n",
    "               segment_length,\n",
    "               runs,\n",
    "               filt_num,\n",
    "               kernel_num,\n",
    "               dilation,\n",
    "               stack,\n",
    "               learn_r,\n",
    "               drop_rate,\n",
    "               Model_num):\n",
    "    \n",
    "    \n",
    "        \n",
    "    time1 = timer()\n",
    "        \n",
    "    working_dir = Path('.')\n",
    "    model_path = working_dir / 'Model' / ('Model_{}_k{}_s{}_di{}_dr{}_L{}.H5'.format(Model_num, kernel_num, stack, dilation, drop_rate, segment_length))\n",
    "    \n",
    "    \n",
    "\n",
    "    #seg_length = None\n",
    "    time_out = timer()-time1\n",
    "    print('Time till start of create model %s' % time_out)\n",
    "    time2 = timer()\n",
    "    model = create_model(num_feat=1,\n",
    "                         num_classes=4,\n",
    "                         filt_num=filt_num,\n",
    "                         kernel_num=kernel_num,\n",
    "                         stack=stack,\n",
    "                         dilation=dilation,\n",
    "                         lr=learn_r,\n",
    "                         drop_rate=drop_rate,\n",
    "                         segment_length = segment_length,\n",
    "                         use_skip=True,\n",
    "                         opt='adam')\n",
    "\n",
    "    time3 = timer()\n",
    "    time_out = time3-time2\n",
    "    print('Time to create model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        history = model.fit(train_data,\n",
    "                  epochs=runs,\n",
    "                  verbose=2,\n",
    "                  callbacks=callback,\n",
    "                  validation_data=test_dataset)\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    time_out = timer()-time3\n",
    "    print('Time to fit model %s' % time_out)\n",
    "    with mirrored_strategy.scope():\n",
    "        y_preds = model.predict(Val_dataset,\n",
    "                                       verbose=0,\n",
    "                                       callbacks=callback,\n",
    "                                      )\n",
    "        y_argmax2 = np.argmax(y_preds,axis=1)\n",
    "        predict_labels = np.squeeze(predict_labels[:], axis=1)\n",
    "        #for pred1, pred2, pred3, pred4 in y_pred:\n",
    "        #y_argmax = []\n",
    "        #i=0\n",
    "        perc_score = tf.dtypes.cast((sum(pred_accuracy(predict_labels, y_argmax2))/(len(predict_labels))), tf.float16)\n",
    "        Accuracy_test = float(perc_score)\n",
    "        print('Prediction Accuracy: %s' % Accuracy_test)\n",
    "        con_mat = metrics.confusion_matrix(predict_labels, y_argmax2)\n",
    "        class_report = metrics.classification_report(predict_labels, y_argmax2, digits=3)\n",
    "        print(con_mat, '\\n\\n')\n",
    "        print(class_report, '\\n\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    d = {'segment length':[segment_length], 'filters': [filt_num], 'kernel size': [kernel_num], 'stacks':[stack], 'dropout': [drop_rate], 'lr': [learn_r], 'dilation': [dilation], 'Training Time': time_out, 'train loss': [history.history['loss'][-1]], 'train acc': [history.history['sparse_categorical_accuracy'][-1]], 'eval acc': [history.history['val_sparse_categorical_accuracy'][-1]], 'Eval Acc': [Accuracy_test],'C1 correct': [con_mat[0][0]], 'C1 as C2':[con_mat[0][1]], 'C1 as C3':[con_mat[0][2]], 'C1 as C4':[con_mat[0][3]],'C2 as C1': [con_mat[1][0]], 'C2 correct':[con_mat[1][1]], 'C2 as C3':[con_mat[1][2]], 'C2 as C4':[con_mat[1][3]],'C3 as C1': [con_mat[2][0]], 'C3 as C2':[con_mat[2][1]], 'C3 correct':[con_mat[2][2]], 'C3 as C4':[con_mat[2][3]],'C4 as C1': [con_mat[3][0]], 'C4 as C2':[con_mat[3][1]], 'C4 as C3':[con_mat[3][2]], 'C4 correct':[con_mat[3][3]]}\n",
    "    \n",
    "    \n",
    "    append_list2_in = pd.DataFrame.from_dict(d)\n",
    "       \n",
    "    time_out = timer()-time1\n",
    "    print('Total Time %s' % time_out)\n",
    "    \n",
    "    return model, history, y_preds, append_list2_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bc396-4658-4733-a0da-28538f2399e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "153bc396-4658-4733-a0da-28538f2399e4",
    "outputId": "0718584f-69bc-4f29-fdbb-44d712b98742",
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_size = 256 #normally 2048 but 512 on colab\n",
    "b_size2 = int(b_size / 4)\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "with mirrored_strategy.scope():\n",
    "    train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "waste_split = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb526f-faba-43ce-9232-3990cfb965bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    val_dataset, X_v1, predict_labels= create_pred_batch(Val_path=Val_path, segment_length=segment_length, step_length=step_size, b_size=int(b_size/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb548e3-948f-4df7-942f-d90ec7ab68eb",
   "metadata": {
    "id": "3fb548e3-948f-4df7-942f-d90ec7ab68eb"
   },
   "source": [
    "# Batch Norm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cebdd3d9-315e-4c80-9822-93d013e5d3d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d62323b-d48e-4217-8a88-9b4e6cd2b9a6",
    "outputId": "50c24f3c-151f-4a84-b36c-ee1f9a77f65e",
    "tags": []
   },
   "source": [
    "tf.keras.backend.clear_session()\n",
    "Learning_Rate = 0.0125\n",
    "Drop_rate = 0.175\n",
    "Repeats = 75\n",
    "m_count =2\n",
    "print('Model Number %s' % m_count)\n",
    "with mirrored_strategy.scope():\n",
    "    b_size = 256 #normally 2048 but 512 on colab\n",
    "    b_size2 = int(b_size / 4)\n",
    "    step_size = 300\n",
    "    step_length=step_size\n",
    "    segment_length = 2400\n",
    "    train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "    val_dataset, X_v1, predict_labels= create_pred_batch(Val_path=Val_path, segment_length=segment_length, step_length=step_size, b_size=int(b_size/4))\n",
    "    model2, history2, y_preds2, res_list2 = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list2, ignore_index=True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2dfa694-a617-43f9-95df-6d5d6da429d1",
   "metadata": {
    "id": "e838e208-64cd-4fc4-b916-1bcb3fc29448",
    "outputId": "66dd8a54-5229-4da3-fd49-921b7eb2a5bd",
    "tags": []
   },
   "source": [
    "m_count =2\n",
    "print('Model Number %s' % m_count)\n",
    "tf.keras.backend.clear_session()\n",
    "with mirrored_strategy.scope():\n",
    "    model2, history2, y_preds2, res_list2 = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=0.3,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list3, ignore_index=True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d5748-a3e9-449d-8b54-030e531aa8b1",
   "metadata": {
    "id": "cd4d5748-a3e9-449d-8b54-030e531aa8b1"
   },
   "outputs": [],
   "source": [
    "append_list_time1.sort_values(by=['segment length', 'kernel size', 'stacks', 'dilation', 'filters'], ascending=[True, False, False, False, True])\n",
    "append_list_time1.to_csv(r'{}.csv'.format('List_Check_300'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1570ba-1772-4251-827f-fef44b4e1a50",
   "metadata": {
    "id": "8a1570ba-1772-4251-827f-fef44b4e1a50"
   },
   "outputs": [],
   "source": [
    "append_list_time1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd369cd-6f1f-4962-999f-b2598bebcb3c",
   "metadata": {
    "id": "0fd369cd-6f1f-4962-999f-b2598bebcb3c"
   },
   "source": [
    "# Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2c9755-25f6-4cd1-befe-361ec374512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sig Divide Time: 1.4923975467681885\n",
      "Sig Divide Time: 8.276552438735962\n",
      "Sig Divide Time: 1.1134204864501953\n",
      "Model Number 1\n",
      "Time till start of create model 7.225000081234612e-05\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Receptive Field Size: 2541\n",
      "x.shape= (None, 16)\n",
      "model.x = (None, 2400, 1)\n",
      "model.y = (None, 4)\n",
      "Filter Length: 16\n",
      "Kernel Size: 11\n",
      "Dilation: 7\n",
      "Learning Rate: 0.0125\n",
      "Dropout Rate: 0.175\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2400, 1)]         0         \n",
      "_________________________________________________________________\n",
      "Model (TCN)                  (None, 16)                37936     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 38,004\n",
      "Trainable params: 37,556\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Time to create model 1.0083706959994743\n",
      "Epoch 1/75\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 60 all-reduces with algorithm = nccl, num_packs = 1\n",
      "54/54 - 77s - loss: 1.1260 - sparse_categorical_accuracy: 0.4729 - val_loss: 2.5678 - val_sparse_categorical_accuracy: 0.2801\n",
      "Epoch 2/75\n",
      "54/54 - 53s - loss: 0.8753 - sparse_categorical_accuracy: 0.5960 - val_loss: 2.1914 - val_sparse_categorical_accuracy: 0.4309\n",
      "Epoch 3/75\n",
      "54/54 - 52s - loss: 0.6993 - sparse_categorical_accuracy: 0.6801 - val_loss: 4.4748 - val_sparse_categorical_accuracy: 0.2899\n",
      "Epoch 4/75\n",
      "54/54 - 55s - loss: 0.4631 - sparse_categorical_accuracy: 0.8053 - val_loss: 2.0413 - val_sparse_categorical_accuracy: 0.4291\n",
      "Epoch 5/75\n",
      "54/54 - 53s - loss: 0.3143 - sparse_categorical_accuracy: 0.8764 - val_loss: 2.0169 - val_sparse_categorical_accuracy: 0.5814\n",
      "Epoch 6/75\n",
      "54/54 - 52s - loss: 0.2177 - sparse_categorical_accuracy: 0.9185 - val_loss: 1.5666 - val_sparse_categorical_accuracy: 0.6314\n",
      "Epoch 7/75\n",
      "54/54 - 52s - loss: 0.1647 - sparse_categorical_accuracy: 0.9397 - val_loss: 1.9938 - val_sparse_categorical_accuracy: 0.5897\n",
      "Epoch 8/75\n",
      "54/54 - 53s - loss: 0.1226 - sparse_categorical_accuracy: 0.9567 - val_loss: 1.6085 - val_sparse_categorical_accuracy: 0.7614\n",
      "Epoch 9/75\n",
      "54/54 - 55s - loss: 0.1057 - sparse_categorical_accuracy: 0.9628 - val_loss: 1.6683 - val_sparse_categorical_accuracy: 0.8170\n",
      "Epoch 10/75\n",
      "54/54 - 52s - loss: 0.0896 - sparse_categorical_accuracy: 0.9686 - val_loss: 1.1680 - val_sparse_categorical_accuracy: 0.8797\n",
      "Epoch 11/75\n",
      "54/54 - 52s - loss: 0.0784 - sparse_categorical_accuracy: 0.9735 - val_loss: 1.1825 - val_sparse_categorical_accuracy: 0.8649\n",
      "Epoch 12/75\n",
      "54/54 - 52s - loss: 0.0693 - sparse_categorical_accuracy: 0.9765 - val_loss: 1.5152 - val_sparse_categorical_accuracy: 0.7893\n",
      "Epoch 13/75\n",
      "54/54 - 53s - loss: 0.0600 - sparse_categorical_accuracy: 0.9799 - val_loss: 3.6348 - val_sparse_categorical_accuracy: 0.7516\n",
      "Epoch 14/75\n",
      "54/54 - 55s - loss: 0.0526 - sparse_categorical_accuracy: 0.9822 - val_loss: 2.1438 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 15/75\n",
      "54/54 - 52s - loss: 0.0540 - sparse_categorical_accuracy: 0.9819 - val_loss: 1.3492 - val_sparse_categorical_accuracy: 0.8913\n",
      "Epoch 16/75\n",
      "54/54 - 52s - loss: 0.0481 - sparse_categorical_accuracy: 0.9841 - val_loss: 1.7543 - val_sparse_categorical_accuracy: 0.8046\n",
      "Epoch 17/75\n",
      "54/54 - 52s - loss: 0.0458 - sparse_categorical_accuracy: 0.9848 - val_loss: 1.5846 - val_sparse_categorical_accuracy: 0.8557\n",
      "Epoch 18/75\n",
      "54/54 - 53s - loss: 0.0467 - sparse_categorical_accuracy: 0.9845 - val_loss: 2.5514 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 19/75\n",
      "54/54 - 55s - loss: 0.0383 - sparse_categorical_accuracy: 0.9873 - val_loss: 1.7861 - val_sparse_categorical_accuracy: 0.8294\n",
      "Epoch 20/75\n",
      "54/54 - 53s - loss: 0.0394 - sparse_categorical_accuracy: 0.9869 - val_loss: 2.4792 - val_sparse_categorical_accuracy: 0.7642\n",
      "Epoch 21/75\n",
      "54/54 - 52s - loss: 0.0359 - sparse_categorical_accuracy: 0.9886 - val_loss: 1.7414 - val_sparse_categorical_accuracy: 0.8484\n",
      "Epoch 22/75\n",
      "54/54 - 53s - loss: 0.0333 - sparse_categorical_accuracy: 0.9890 - val_loss: 2.5697 - val_sparse_categorical_accuracy: 0.7425\n",
      "Epoch 23/75\n",
      "54/54 - 53s - loss: 0.0328 - sparse_categorical_accuracy: 0.9890 - val_loss: 1.4176 - val_sparse_categorical_accuracy: 0.9019\n",
      "Epoch 24/75\n",
      "54/54 - 55s - loss: 0.0314 - sparse_categorical_accuracy: 0.9895 - val_loss: 1.6118 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 25/75\n",
      "54/54 - 52s - loss: 0.0320 - sparse_categorical_accuracy: 0.9892 - val_loss: 1.6459 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 26/75\n",
      "54/54 - 52s - loss: 0.0294 - sparse_categorical_accuracy: 0.9902 - val_loss: 1.7309 - val_sparse_categorical_accuracy: 0.8990\n",
      "Epoch 27/75\n",
      "54/54 - 52s - loss: 0.0286 - sparse_categorical_accuracy: 0.9906 - val_loss: 1.9215 - val_sparse_categorical_accuracy: 0.8723\n",
      "Epoch 28/75\n",
      "54/54 - 54s - loss: 0.0267 - sparse_categorical_accuracy: 0.9912 - val_loss: 1.4970 - val_sparse_categorical_accuracy: 0.8818\n",
      "Epoch 29/75\n",
      "54/54 - 54s - loss: 0.0253 - sparse_categorical_accuracy: 0.9914 - val_loss: 1.5712 - val_sparse_categorical_accuracy: 0.8790\n",
      "Epoch 30/75\n",
      "54/54 - 52s - loss: 0.0263 - sparse_categorical_accuracy: 0.9915 - val_loss: 2.6895 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 31/75\n",
      "54/54 - 52s - loss: 0.0234 - sparse_categorical_accuracy: 0.9926 - val_loss: 2.5853 - val_sparse_categorical_accuracy: 0.8298\n",
      "Epoch 32/75\n",
      "54/54 - 52s - loss: 0.0233 - sparse_categorical_accuracy: 0.9923 - val_loss: 1.5768 - val_sparse_categorical_accuracy: 0.8247\n",
      "Epoch 33/75\n",
      "54/54 - 54s - loss: 0.0219 - sparse_categorical_accuracy: 0.9929 - val_loss: 1.5732 - val_sparse_categorical_accuracy: 0.8421\n",
      "Epoch 34/75\n",
      "54/54 - 53s - loss: 0.0228 - sparse_categorical_accuracy: 0.9925 - val_loss: 1.4831 - val_sparse_categorical_accuracy: 0.9243\n",
      "Epoch 35/75\n",
      "54/54 - 52s - loss: 0.0216 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.3986 - val_sparse_categorical_accuracy: 0.9124\n",
      "Epoch 36/75\n",
      "54/54 - 52s - loss: 0.0196 - sparse_categorical_accuracy: 0.9937 - val_loss: 3.1771 - val_sparse_categorical_accuracy: 0.7534\n",
      "Epoch 37/75\n",
      "54/54 - 52s - loss: 0.0231 - sparse_categorical_accuracy: 0.9923 - val_loss: 2.6975 - val_sparse_categorical_accuracy: 0.7697\n",
      "Epoch 38/75\n",
      "54/54 - 55s - loss: 0.0212 - sparse_categorical_accuracy: 0.9932 - val_loss: 1.7892 - val_sparse_categorical_accuracy: 0.8606\n",
      "Epoch 39/75\n",
      "54/54 - 53s - loss: 0.0202 - sparse_categorical_accuracy: 0.9935 - val_loss: 2.1860 - val_sparse_categorical_accuracy: 0.8612\n",
      "Epoch 40/75\n",
      "54/54 - 52s - loss: 0.0183 - sparse_categorical_accuracy: 0.9944 - val_loss: 2.2127 - val_sparse_categorical_accuracy: 0.8576\n",
      "Epoch 41/75\n",
      "54/54 - 52s - loss: 0.0199 - sparse_categorical_accuracy: 0.9936 - val_loss: 2.0563 - val_sparse_categorical_accuracy: 0.8699\n",
      "Epoch 42/75\n",
      "54/54 - 52s - loss: 0.0193 - sparse_categorical_accuracy: 0.9937 - val_loss: 2.0440 - val_sparse_categorical_accuracy: 0.8969\n",
      "Epoch 43/75\n",
      "54/54 - 55s - loss: 0.0179 - sparse_categorical_accuracy: 0.9942 - val_loss: 1.5495 - val_sparse_categorical_accuracy: 0.9116\n",
      "Epoch 44/75\n",
      "54/54 - 52s - loss: 0.0174 - sparse_categorical_accuracy: 0.9945 - val_loss: 1.5999 - val_sparse_categorical_accuracy: 0.9169\n",
      "Epoch 45/75\n",
      "54/54 - 52s - loss: 0.0183 - sparse_categorical_accuracy: 0.9939 - val_loss: 1.3551 - val_sparse_categorical_accuracy: 0.8641\n",
      "Epoch 46/75\n",
      "54/54 - 52s - loss: 0.0165 - sparse_categorical_accuracy: 0.9948 - val_loss: 1.8583 - val_sparse_categorical_accuracy: 0.8562\n",
      "Epoch 47/75\n",
      "54/54 - 53s - loss: 0.0163 - sparse_categorical_accuracy: 0.9946 - val_loss: 1.9254 - val_sparse_categorical_accuracy: 0.8405\n",
      "Epoch 48/75\n",
      "54/54 - 55s - loss: 0.0156 - sparse_categorical_accuracy: 0.9952 - val_loss: 2.3207 - val_sparse_categorical_accuracy: 0.8485\n",
      "Epoch 49/75\n",
      "54/54 - 52s - loss: 0.0166 - sparse_categorical_accuracy: 0.9947 - val_loss: 2.9340 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 50/75\n",
      "54/54 - 52s - loss: 0.0173 - sparse_categorical_accuracy: 0.9945 - val_loss: 2.0694 - val_sparse_categorical_accuracy: 0.8480\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0037500000558793544.\n",
      "Epoch 51/75\n",
      "54/54 - 53s - loss: 0.0122 - sparse_categorical_accuracy: 0.9962 - val_loss: 2.1372 - val_sparse_categorical_accuracy: 0.8433\n",
      "Epoch 52/75\n",
      "54/54 - 54s - loss: 0.0086 - sparse_categorical_accuracy: 0.9973 - val_loss: 2.1979 - val_sparse_categorical_accuracy: 0.8544\n",
      "Epoch 53/75\n",
      "54/54 - 54s - loss: 0.0091 - sparse_categorical_accuracy: 0.9972 - val_loss: 2.0145 - val_sparse_categorical_accuracy: 0.8751\n",
      "Epoch 54/75\n",
      "54/54 - 52s - loss: 0.0086 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.7345 - val_sparse_categorical_accuracy: 0.8939\n",
      "Epoch 55/75\n",
      "54/54 - 52s - loss: 0.0076 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.9378 - val_sparse_categorical_accuracy: 0.8829\n",
      "Epoch 56/75\n",
      "54/54 - 53s - loss: 0.0076 - sparse_categorical_accuracy: 0.9974 - val_loss: 2.3660 - val_sparse_categorical_accuracy: 0.8604\n",
      "Epoch 57/75\n",
      "54/54 - 54s - loss: 0.0080 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.8120 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 58/75\n",
      "54/54 - 54s - loss: 0.0081 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.9693 - val_sparse_categorical_accuracy: 0.9187\n",
      "Epoch 59/75\n",
      "54/54 - 52s - loss: 0.0081 - sparse_categorical_accuracy: 0.9974 - val_loss: 2.1357 - val_sparse_categorical_accuracy: 0.8669\n",
      "Epoch 60/75\n",
      "54/54 - 53s - loss: 0.0080 - sparse_categorical_accuracy: 0.9976 - val_loss: 2.2087 - val_sparse_categorical_accuracy: 0.8814\n",
      "Epoch 61/75\n",
      "54/54 - 52s - loss: 0.0086 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.8789 - val_sparse_categorical_accuracy: 0.9075\n",
      "Epoch 62/75\n",
      "54/54 - 55s - loss: 0.0073 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.7305 - val_sparse_categorical_accuracy: 0.9040\n",
      "Epoch 63/75\n",
      "54/54 - 53s - loss: 0.0066 - sparse_categorical_accuracy: 0.9978 - val_loss: 1.8023 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 64/75\n",
      "54/54 - 52s - loss: 0.0083 - sparse_categorical_accuracy: 0.9974 - val_loss: 2.6708 - val_sparse_categorical_accuracy: 0.8080\n",
      "Epoch 65/75\n",
      "54/54 - 52s - loss: 0.0083 - sparse_categorical_accuracy: 0.9973 - val_loss: 2.0845 - val_sparse_categorical_accuracy: 0.9172\n",
      "Epoch 66/75\n",
      "54/54 - 53s - loss: 0.0078 - sparse_categorical_accuracy: 0.9976 - val_loss: 2.3276 - val_sparse_categorical_accuracy: 0.8565\n",
      "Epoch 67/75\n",
      "54/54 - 55s - loss: 0.0079 - sparse_categorical_accuracy: 0.9975 - val_loss: 1.7987 - val_sparse_categorical_accuracy: 0.9188\n",
      "Epoch 68/75\n",
      "54/54 - 52s - loss: 0.0062 - sparse_categorical_accuracy: 0.9979 - val_loss: 2.9911 - val_sparse_categorical_accuracy: 0.8083\n",
      "Epoch 69/75\n",
      "54/54 - 52s - loss: 0.0079 - sparse_categorical_accuracy: 0.9974 - val_loss: 1.9134 - val_sparse_categorical_accuracy: 0.9224\n",
      "Epoch 70/75\n",
      "54/54 - 53s - loss: 0.0075 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.9905 - val_sparse_categorical_accuracy: 0.9183\n",
      "Epoch 71/75\n",
      "54/54 - 53s - loss: 0.0083 - sparse_categorical_accuracy: 0.9975 - val_loss: 2.5357 - val_sparse_categorical_accuracy: 0.8360\n",
      "Epoch 72/75\n",
      "54/54 - 55s - loss: 0.0082 - sparse_categorical_accuracy: 0.9976 - val_loss: 1.7972 - val_sparse_categorical_accuracy: 0.9236\n",
      "Epoch 73/75\n",
      "54/54 - 52s - loss: 0.0066 - sparse_categorical_accuracy: 0.9979 - val_loss: 1.6391 - val_sparse_categorical_accuracy: 0.9241\n",
      "Epoch 74/75\n",
      "54/54 - 52s - loss: 0.0071 - sparse_categorical_accuracy: 0.9978 - val_loss: 2.4346 - val_sparse_categorical_accuracy: 0.8391\n",
      "Epoch 75/75\n",
      "54/54 - 52s - loss: 0.0076 - sparse_categorical_accuracy: 0.9975 - val_loss: 2.1817 - val_sparse_categorical_accuracy: 0.8841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fit model 4061.794782899\n",
      "Prediction Accuracy: 0.60791015625\n",
      "[[3218    0    0    0]\n",
      " [ 121 2676  173 1060]\n",
      " [   0 1616 2832    0]\n",
      " [   0 3116 1028 2312]] \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     1.000     0.982      3218\n",
      "           1      0.361     0.664     0.468      4030\n",
      "           2      0.702     0.637     0.668      4448\n",
      "           3      0.686     0.358     0.470      6456\n",
      "\n",
      "    accuracy                          0.608     18152\n",
      "   macro avg      0.678     0.665     0.647     18152\n",
      "weighted avg      0.667     0.608     0.609     18152\n",
      " \n",
      "\n",
      "\n",
      "Total Time 4069.883972918\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8be178fff450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mm_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Number %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mm_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     history, y_preds, res_list = train_func2(train_data=train_dataset,\n\u001b[0m\u001b[1;32m     22\u001b[0m                                             \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                             \u001b[0mVal_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "b_size = 2048 #normally 2048 but 512 on colab\n",
    "b_size2 = int(b_size / 4)\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "with mirrored_strategy.scope():\n",
    "    train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "    val_dataset, X_v1, predict_labels= create_pred_batch(Val_path=Val_path, segment_length=segment_length, step_length=step_size, b_size=int(b_size/4))\n",
    "waste_split = 0.1\n",
    "append_list_time1 = pd.DataFrame\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    #Tuned Param dropout\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.175\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 1\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.3\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 2\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29447995-0032-4eb1-8d95-9b97c536a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "b_size = 1024 #normally 2048 but 512 on colab\n",
    "b_size2 = int(b_size / 4)\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "with mirrored_strategy.scope():\n",
    "    train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "waste_split = 0.1\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    #Tuned Param dropout\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.175\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 1\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.3\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 2\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4364762-965a-453d-8987-7b3ddfd6f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "b_size = 512 #normally 2048 but 512 on colab\n",
    "b_size2 = int(b_size / 4)\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "with mirrored_strategy.scope():\n",
    "    train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "    val_dataset, X_v1, predict_labels= create_pred_batch(Val_path=Val_path, segment_length=segment_length, step_length=step_size, b_size=int(b_size/4))\n",
    "waste_split = 0.1\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    #Tuned Param dropout\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.175\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 1\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.3\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 2\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f12ce-e8bb-4d13-9cfd-5b9ea08fddf3",
   "metadata": {
    "id": "d94f12ce-e8bb-4d13-9cfd-5b9ea08fddf3"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "b_size = 256 #normally 2048 but 512 on colab\n",
    "b_size2 = int(b_size / 4)\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "with mirrored_strategy.scope():\n",
    "    train_dataset, test_dataset, y_s1 = Create_Batch(data_path, split_perc, segment_length, step_length, b_size)\n",
    "    val_dataset, X_v1, predict_labels= create_pred_batch(Val_path=Val_path, segment_length=segment_length, step_length=step_size, b_size=int(b_size/4))\n",
    "waste_split = 0.1\n",
    "with mirrored_strategy.scope():\n",
    "    \n",
    "    #Tuned Param dropout\n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.175\n",
    "    Repeats = 75\n",
    "\n",
    "    m_count = 1\n",
    "    append_list_time1 = pd.DataFrame\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "    \n",
    "    Learning_Rate = 0.0125\n",
    "    Drop_rate = 0.3\n",
    "    Repeats = 75\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    m_count = 2\n",
    "    append_list_time1 = pd.DataFrame\n",
    "    print('Model Number %s' % m_count)\n",
    "    history, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                            test_dataset=test_dataset,\n",
    "                                            Val_dataset=val_dataset,\n",
    "                                            predict_labels=predict_labels, \n",
    "                                            filt_num=16,\n",
    "                                            kernel_num=11,\n",
    "                                            dilation=7,\n",
    "                                            stack=1,\n",
    "                                            learn_r=Learning_Rate,\n",
    "                                            drop_rate=Drop_rate,\n",
    "                                            runs=Repeats,\n",
    "                                            Model_num = m_count, \n",
    "                                            segment_length = segment_length)\n",
    "\n",
    "    append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "    tf.keras.backend.clear_session()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfddbe-d24f-4f6f-9255-46786b9c2074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
