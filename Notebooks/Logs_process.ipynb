{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = [str(i) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_log = pd.read_csv('step_200_2/a2.k6D7s2f32_2400_200.txt', '-', names = my_cols, header=None).dropna(axis=0).reset_index(drop = True)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64/64</td>\n",
       "      <td>87s</td>\n",
       "      <td>loss: 0.9375</td>\n",
       "      <td>sparse_categorical_accuracy: 0.6397</td>\n",
       "      <td>val_loss: 1.1871</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.6680</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7390</td>\n",
       "      <td>val_loss: 1.1278</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.4901</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8016</td>\n",
       "      <td>val_loss: 0.8852</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.3910</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8383</td>\n",
       "      <td>val_loss: 1.1684</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.3529</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8587</td>\n",
       "      <td>val_loss: 0.7156</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.7559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.2496</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9024</td>\n",
       "      <td>val_loss: 0.6076</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.7728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.1614</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9419</td>\n",
       "      <td>val_loss: 0.4530</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.1065</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9633</td>\n",
       "      <td>val_loss: 0.5594</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0743</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9749</td>\n",
       "      <td>val_loss: 0.7690</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.7786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0568</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9811</td>\n",
       "      <td>val_loss: 0.8438</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.7952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0405</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9872</td>\n",
       "      <td>val_loss: 0.7931</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.7571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0251</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9919</td>\n",
       "      <td>val_loss: 0.3192</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.9076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0231</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9925</td>\n",
       "      <td>val_loss: 0.3544</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0181</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9938</td>\n",
       "      <td>val_loss: 0.3860</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0152</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9952</td>\n",
       "      <td>val_loss: 0.3535</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.9033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0162</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9948</td>\n",
       "      <td>val_loss: 0.3637</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.9043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0139</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9956</td>\n",
       "      <td>val_loss: 0.4654</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0123</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9963</td>\n",
       "      <td>val_loss: 0.5277</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0126</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9960</td>\n",
       "      <td>val_loss: 0.4921</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0100</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9968</td>\n",
       "      <td>val_loss: 0.4026</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0089</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9972</td>\n",
       "      <td>val_loss: 0.5243</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0099</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9970</td>\n",
       "      <td>val_loss: 0.5819</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0079</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9978</td>\n",
       "      <td>val_loss: 0.4335</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0076</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9976</td>\n",
       "      <td>val_loss: 0.3848</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.9015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0086</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9972</td>\n",
       "      <td>val_loss: 0.4132</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0072</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9977</td>\n",
       "      <td>val_loss: 0.4228</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>64/64</td>\n",
       "      <td>51s</td>\n",
       "      <td>loss: 0.0071</td>\n",
       "      <td>sparse_categorical_accuracy: 0.9980</td>\n",
       "      <td>val_loss: 0.5232</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.8702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1               2                                      3  \\\n",
       "0   64/64    87s    loss: 0.9375    sparse_categorical_accuracy: 0.6397    \n",
       "1   64/64    51s    loss: 0.6680    sparse_categorical_accuracy: 0.7390    \n",
       "2   64/64    51s    loss: 0.4901    sparse_categorical_accuracy: 0.8016    \n",
       "3   64/64    51s    loss: 0.3910    sparse_categorical_accuracy: 0.8383    \n",
       "4   64/64    51s    loss: 0.3529    sparse_categorical_accuracy: 0.8587    \n",
       "5   64/64    51s    loss: 0.2496    sparse_categorical_accuracy: 0.9024    \n",
       "6   64/64    51s    loss: 0.1614    sparse_categorical_accuracy: 0.9419    \n",
       "7   64/64    51s    loss: 0.1065    sparse_categorical_accuracy: 0.9633    \n",
       "8   64/64    51s    loss: 0.0743    sparse_categorical_accuracy: 0.9749    \n",
       "9   64/64    51s    loss: 0.0568    sparse_categorical_accuracy: 0.9811    \n",
       "10  64/64    51s    loss: 0.0405    sparse_categorical_accuracy: 0.9872    \n",
       "11  64/64    51s    loss: 0.0251    sparse_categorical_accuracy: 0.9919    \n",
       "12  64/64    51s    loss: 0.0231    sparse_categorical_accuracy: 0.9925    \n",
       "13  64/64    51s    loss: 0.0181    sparse_categorical_accuracy: 0.9938    \n",
       "14  64/64    51s    loss: 0.0152    sparse_categorical_accuracy: 0.9952    \n",
       "15  64/64    51s    loss: 0.0162    sparse_categorical_accuracy: 0.9948    \n",
       "16  64/64    51s    loss: 0.0139    sparse_categorical_accuracy: 0.9956    \n",
       "17  64/64    51s    loss: 0.0123    sparse_categorical_accuracy: 0.9963    \n",
       "18  64/64    51s    loss: 0.0126    sparse_categorical_accuracy: 0.9960    \n",
       "19  64/64    51s    loss: 0.0100    sparse_categorical_accuracy: 0.9968    \n",
       "20  64/64    51s    loss: 0.0089    sparse_categorical_accuracy: 0.9972    \n",
       "21  64/64    51s    loss: 0.0099    sparse_categorical_accuracy: 0.9970    \n",
       "22  64/64    51s    loss: 0.0079    sparse_categorical_accuracy: 0.9978    \n",
       "23  64/64    51s    loss: 0.0076    sparse_categorical_accuracy: 0.9976    \n",
       "24  64/64    51s    loss: 0.0086    sparse_categorical_accuracy: 0.9972    \n",
       "25  64/64    51s    loss: 0.0072    sparse_categorical_accuracy: 0.9977    \n",
       "26  64/64    51s    loss: 0.0071    sparse_categorical_accuracy: 0.9980    \n",
       "\n",
       "                     4                                         5  \n",
       "0    val_loss: 1.1871    val_sparse_categorical_accuracy: 0.4152  \n",
       "1    val_loss: 1.1278    val_sparse_categorical_accuracy: 0.4328  \n",
       "2    val_loss: 0.8852    val_sparse_categorical_accuracy: 0.5197  \n",
       "3    val_loss: 1.1684    val_sparse_categorical_accuracy: 0.6852  \n",
       "4    val_loss: 0.7156    val_sparse_categorical_accuracy: 0.7559  \n",
       "5    val_loss: 0.6076    val_sparse_categorical_accuracy: 0.7728  \n",
       "6    val_loss: 0.4530    val_sparse_categorical_accuracy: 0.8365  \n",
       "7    val_loss: 0.5594    val_sparse_categorical_accuracy: 0.8049  \n",
       "8    val_loss: 0.7690    val_sparse_categorical_accuracy: 0.7786  \n",
       "9    val_loss: 0.8438    val_sparse_categorical_accuracy: 0.7952  \n",
       "10   val_loss: 0.7931    val_sparse_categorical_accuracy: 0.7571  \n",
       "11   val_loss: 0.3192    val_sparse_categorical_accuracy: 0.9076  \n",
       "12   val_loss: 0.3544    val_sparse_categorical_accuracy: 0.8888  \n",
       "13   val_loss: 0.3860    val_sparse_categorical_accuracy: 0.8871  \n",
       "14   val_loss: 0.3535    val_sparse_categorical_accuracy: 0.9033  \n",
       "15   val_loss: 0.3637    val_sparse_categorical_accuracy: 0.9043  \n",
       "16   val_loss: 0.4654    val_sparse_categorical_accuracy: 0.8775  \n",
       "17   val_loss: 0.5277    val_sparse_categorical_accuracy: 0.8642  \n",
       "18   val_loss: 0.4921    val_sparse_categorical_accuracy: 0.8701  \n",
       "19   val_loss: 0.4026    val_sparse_categorical_accuracy: 0.8947  \n",
       "20   val_loss: 0.5243    val_sparse_categorical_accuracy: 0.8597  \n",
       "21   val_loss: 0.5819    val_sparse_categorical_accuracy: 0.8587  \n",
       "22   val_loss: 0.4335    val_sparse_categorical_accuracy: 0.8859  \n",
       "23   val_loss: 0.3848    val_sparse_categorical_accuracy: 0.9015  \n",
       "24   val_loss: 0.4132    val_sparse_categorical_accuracy: 0.8931  \n",
       "25   val_loss: 0.4228    val_sparse_categorical_accuracy: 0.8900  \n",
       "26   val_loss: 0.5232    val_sparse_categorical_accuracy: 0.8702  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_log2 = pd.read_csv('step_200_2/f3.k16D6s2f64_3600_200.txt', '-', names = my_cols, header=None).reset_index(drop = True)#dropna(axis=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epoch 1/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63/63</td>\n",
       "      <td>122s</td>\n",
       "      <td>loss: 506.3037</td>\n",
       "      <td>sparse_categorical_accuracy: 0.4402</td>\n",
       "      <td>val_loss: 1.3232</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Epoch 2/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 1.1332</td>\n",
       "      <td>sparse_categorical_accuracy: 0.5634</td>\n",
       "      <td>val_loss: 1.3115</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Epoch 3/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.9677</td>\n",
       "      <td>sparse_categorical_accuracy: 0.6236</td>\n",
       "      <td>val_loss: 1.2923</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Epoch 4/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.8607</td>\n",
       "      <td>sparse_categorical_accuracy: 0.6683</td>\n",
       "      <td>val_loss: 1.0922</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Epoch 5/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.7485</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7115</td>\n",
       "      <td>val_loss: 1.0212</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Epoch 6/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.6570</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7480</td>\n",
       "      <td>val_loss: 0.9656</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Epoch 7/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.5812</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7766</td>\n",
       "      <td>val_loss: 1.0279</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Epoch 8/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.5229</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7993</td>\n",
       "      <td>val_loss: 1.0471</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Epoch 9/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.4644</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8220</td>\n",
       "      <td>val_loss: 1.0424</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Epoch 10/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.4334</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8322</td>\n",
       "      <td>val_loss: 1.2364</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Epoch 11/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3793</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8537</td>\n",
       "      <td>val_loss: 1.1673</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Epoch 12/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3599</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8589</td>\n",
       "      <td>val_loss: 1.1352</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Epoch 13/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3508</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8635</td>\n",
       "      <td>val_loss: 1.1804</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Epoch 14/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3400</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8666</td>\n",
       "      <td>val_loss: 1.1189</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Epoch 15/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3226</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8744</td>\n",
       "      <td>val_loss: 1.0730</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Epoch 16/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3117</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8782</td>\n",
       "      <td>val_loss: 1.2335</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Epoch 17/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3055</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8779</td>\n",
       "      <td>val_loss: 1.2702</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Epoch 18/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2882</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8860</td>\n",
       "      <td>val_loss: 1.0921</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Epoch 19/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2780</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8899</td>\n",
       "      <td>val_loss: 1.1386</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Epoch 20/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2731</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8910</td>\n",
       "      <td>val_loss: 1.1094</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Epoch 21/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2688</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8926</td>\n",
       "      <td>val_loss: 1.0683</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Time: 2094.4155336770054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[==============================]</td>\n",
       "      <td>5s 115ms/step</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Prediction Accuracy: 0.79296875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[[251  17   0   0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[ 12 345  44   0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[  0   0 131   1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[  0  65  68  66]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>precision    recall  f1</td>\n",
       "      <td>score   support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0      0.954     0.937     0.945   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1      0.808     0.860     0.833   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2      0.539     0.992     0.699   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3      0.985     0.332     0.496   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>accuracy                          0.793   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>macro avg      0.822     0.780     0.743   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>weighted avg      0.847     0.793     0.779   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0                1  \\\n",
       "0                                          Epoch 1/75              NaN   \n",
       "1                                              63/63             122s    \n",
       "2                                          Epoch 2/75              NaN   \n",
       "3                                              63/63              98s    \n",
       "4                                          Epoch 3/75              NaN   \n",
       "5                                              63/63              98s    \n",
       "6                                          Epoch 4/75              NaN   \n",
       "7                                              63/63              98s    \n",
       "8                                          Epoch 5/75              NaN   \n",
       "9                                              63/63              98s    \n",
       "10                                         Epoch 6/75              NaN   \n",
       "11                                             63/63              98s    \n",
       "12                                         Epoch 7/75              NaN   \n",
       "13                                             63/63              98s    \n",
       "14                                         Epoch 8/75              NaN   \n",
       "15                                             63/63              98s    \n",
       "16                                         Epoch 9/75              NaN   \n",
       "17                                             63/63              98s    \n",
       "18                                        Epoch 10/75              NaN   \n",
       "19                                             63/63              98s    \n",
       "20                                        Epoch 11/75              NaN   \n",
       "21                                             63/63              98s    \n",
       "22                                        Epoch 12/75              NaN   \n",
       "23                                             63/63              98s    \n",
       "24                                        Epoch 13/75              NaN   \n",
       "25                                             63/63              98s    \n",
       "26                                        Epoch 14/75              NaN   \n",
       "27                                             63/63              98s    \n",
       "28                                        Epoch 15/75              NaN   \n",
       "29                                             63/63              98s    \n",
       "30                                        Epoch 16/75              NaN   \n",
       "31                                             63/63              98s    \n",
       "32                                        Epoch 17/75              NaN   \n",
       "33                                             63/63              98s    \n",
       "34                                        Epoch 18/75              NaN   \n",
       "35                                             63/63              98s    \n",
       "36                                        Epoch 19/75              NaN   \n",
       "37                                             63/63              98s    \n",
       "38                                        Epoch 20/75              NaN   \n",
       "39                                             63/63              98s    \n",
       "40                                        Epoch 21/75              NaN   \n",
       "41                                             63/63              98s    \n",
       "42                           Time: 2094.4155336770054              NaN   \n",
       "43                  [==============================]     5s 115ms/step   \n",
       "44                    Prediction Accuracy: 0.79296875              NaN   \n",
       "45                                 [[251  17   0   0]              NaN   \n",
       "46                                  [ 12 345  44   0]              NaN   \n",
       "47                                  [  0   0 131   1]              NaN   \n",
       "48                                [  0  65  68  66]]               NaN   \n",
       "49                            precision    recall  f1  score   support   \n",
       "50             0      0.954     0.937     0.945   ...              NaN   \n",
       "51             1      0.808     0.860     0.833   ...              NaN   \n",
       "52             2      0.539     0.992     0.699   ...              NaN   \n",
       "53             3      0.985     0.332     0.496   ...              NaN   \n",
       "54      accuracy                          0.793   ...              NaN   \n",
       "55     macro avg      0.822     0.780     0.743   ...              NaN   \n",
       "56  weighted avg      0.847     0.793     0.779   ...              NaN   \n",
       "\n",
       "                   2                                      3  \\\n",
       "0                NaN                                    NaN   \n",
       "1    loss: 506.3037    sparse_categorical_accuracy: 0.4402    \n",
       "2                NaN                                    NaN   \n",
       "3      loss: 1.1332    sparse_categorical_accuracy: 0.5634    \n",
       "4                NaN                                    NaN   \n",
       "5      loss: 0.9677    sparse_categorical_accuracy: 0.6236    \n",
       "6                NaN                                    NaN   \n",
       "7      loss: 0.8607    sparse_categorical_accuracy: 0.6683    \n",
       "8                NaN                                    NaN   \n",
       "9      loss: 0.7485    sparse_categorical_accuracy: 0.7115    \n",
       "10               NaN                                    NaN   \n",
       "11     loss: 0.6570    sparse_categorical_accuracy: 0.7480    \n",
       "12               NaN                                    NaN   \n",
       "13     loss: 0.5812    sparse_categorical_accuracy: 0.7766    \n",
       "14               NaN                                    NaN   \n",
       "15     loss: 0.5229    sparse_categorical_accuracy: 0.7993    \n",
       "16               NaN                                    NaN   \n",
       "17     loss: 0.4644    sparse_categorical_accuracy: 0.8220    \n",
       "18               NaN                                    NaN   \n",
       "19     loss: 0.4334    sparse_categorical_accuracy: 0.8322    \n",
       "20               NaN                                    NaN   \n",
       "21     loss: 0.3793    sparse_categorical_accuracy: 0.8537    \n",
       "22               NaN                                    NaN   \n",
       "23     loss: 0.3599    sparse_categorical_accuracy: 0.8589    \n",
       "24               NaN                                    NaN   \n",
       "25     loss: 0.3508    sparse_categorical_accuracy: 0.8635    \n",
       "26               NaN                                    NaN   \n",
       "27     loss: 0.3400    sparse_categorical_accuracy: 0.8666    \n",
       "28               NaN                                    NaN   \n",
       "29     loss: 0.3226    sparse_categorical_accuracy: 0.8744    \n",
       "30               NaN                                    NaN   \n",
       "31     loss: 0.3117    sparse_categorical_accuracy: 0.8782    \n",
       "32               NaN                                    NaN   \n",
       "33     loss: 0.3055    sparse_categorical_accuracy: 0.8779    \n",
       "34               NaN                                    NaN   \n",
       "35     loss: 0.2882    sparse_categorical_accuracy: 0.8860    \n",
       "36               NaN                                    NaN   \n",
       "37     loss: 0.2780    sparse_categorical_accuracy: 0.8899    \n",
       "38               NaN                                    NaN   \n",
       "39     loss: 0.2731    sparse_categorical_accuracy: 0.8910    \n",
       "40               NaN                                    NaN   \n",
       "41     loss: 0.2688    sparse_categorical_accuracy: 0.8926    \n",
       "42               NaN                                    NaN   \n",
       "43               NaN                                    NaN   \n",
       "44               NaN                                    NaN   \n",
       "45               NaN                                    NaN   \n",
       "46               NaN                                    NaN   \n",
       "47               NaN                                    NaN   \n",
       "48               NaN                                    NaN   \n",
       "49               NaN                                    NaN   \n",
       "50               NaN                                    NaN   \n",
       "51               NaN                                    NaN   \n",
       "52               NaN                                    NaN   \n",
       "53               NaN                                    NaN   \n",
       "54               NaN                                    NaN   \n",
       "55               NaN                                    NaN   \n",
       "56               NaN                                    NaN   \n",
       "\n",
       "                     4                                         5  \n",
       "0                  NaN                                       NaN  \n",
       "1    val_loss: 1.3232    val_sparse_categorical_accuracy: 0.3848  \n",
       "2                  NaN                                       NaN  \n",
       "3    val_loss: 1.3115    val_sparse_categorical_accuracy: 0.4083  \n",
       "4                  NaN                                       NaN  \n",
       "5    val_loss: 1.2923    val_sparse_categorical_accuracy: 0.4314  \n",
       "6                  NaN                                       NaN  \n",
       "7    val_loss: 1.0922    val_sparse_categorical_accuracy: 0.4688  \n",
       "8                  NaN                                       NaN  \n",
       "9    val_loss: 1.0212    val_sparse_categorical_accuracy: 0.4799  \n",
       "10                 NaN                                       NaN  \n",
       "11   val_loss: 0.9656    val_sparse_categorical_accuracy: 0.5354  \n",
       "12                 NaN                                       NaN  \n",
       "13   val_loss: 1.0279    val_sparse_categorical_accuracy: 0.5225  \n",
       "14                 NaN                                       NaN  \n",
       "15   val_loss: 1.0471    val_sparse_categorical_accuracy: 0.5793  \n",
       "16                 NaN                                       NaN  \n",
       "17   val_loss: 1.0424    val_sparse_categorical_accuracy: 0.6113  \n",
       "18                 NaN                                       NaN  \n",
       "19   val_loss: 1.2364    val_sparse_categorical_accuracy: 0.6192  \n",
       "20                 NaN                                       NaN  \n",
       "21   val_loss: 1.1673    val_sparse_categorical_accuracy: 0.6339  \n",
       "22                 NaN                                       NaN  \n",
       "23   val_loss: 1.1352    val_sparse_categorical_accuracy: 0.6430  \n",
       "24                 NaN                                       NaN  \n",
       "25   val_loss: 1.1804    val_sparse_categorical_accuracy: 0.6523  \n",
       "26                 NaN                                       NaN  \n",
       "27   val_loss: 1.1189    val_sparse_categorical_accuracy: 0.6442  \n",
       "28                 NaN                                       NaN  \n",
       "29   val_loss: 1.0730    val_sparse_categorical_accuracy: 0.6647  \n",
       "30                 NaN                                       NaN  \n",
       "31   val_loss: 1.2335    val_sparse_categorical_accuracy: 0.6635  \n",
       "32                 NaN                                       NaN  \n",
       "33   val_loss: 1.2702    val_sparse_categorical_accuracy: 0.6728  \n",
       "34                 NaN                                       NaN  \n",
       "35   val_loss: 1.0921    val_sparse_categorical_accuracy: 0.6757  \n",
       "36                 NaN                                       NaN  \n",
       "37   val_loss: 1.1386    val_sparse_categorical_accuracy: 0.6890  \n",
       "38                 NaN                                       NaN  \n",
       "39   val_loss: 1.1094    val_sparse_categorical_accuracy: 0.6947  \n",
       "40                 NaN                                       NaN  \n",
       "41   val_loss: 1.0683    val_sparse_categorical_accuracy: 0.6801  \n",
       "42                 NaN                                       NaN  \n",
       "43                 NaN                                       NaN  \n",
       "44                 NaN                                       NaN  \n",
       "45                 NaN                                       NaN  \n",
       "46                 NaN                                       NaN  \n",
       "47                 NaN                                       NaN  \n",
       "48                 NaN                                       NaN  \n",
       "49                 NaN                                       NaN  \n",
       "50                 NaN                                       NaN  \n",
       "51                 NaN                                       NaN  \n",
       "52                 NaN                                       NaN  \n",
       "53                 NaN                                       NaN  \n",
       "54                 NaN                                       NaN  \n",
       "55                 NaN                                       NaN  \n",
       "56                 NaN                                       NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(epoch_log)-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.98876953125\n"
     ]
    }
   ],
   "source": [
    "Pred_acc = epoch_log['0'][len(epoch_log)-13]\n",
    "print(Pred_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      122s \n",
       "1       98s \n",
       "2       98s \n",
       "3       98s \n",
       "4       98s \n",
       "5       98s \n",
       "6       98s \n",
       "7       98s \n",
       "8       98s \n",
       "9       98s \n",
       "10      98s \n",
       "11      98s \n",
       "12      98s \n",
       "13      98s \n",
       "14      98s \n",
       "15      98s \n",
       "16      98s \n",
       "17      98s \n",
       "18      98s \n",
       "19      98s \n",
       "20      98s \n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_log2['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Lambda_Files/Step_txt_logs/f3.k16D6s2f64_3600_400.txt' does not exist: b'Lambda_Files/Step_txt_logs/f3.k16D6s2f64_3600_400.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1fca08c9182f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepoch_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'Lambda_Files/Step_txt_logs/f3.k16D6s2f64_3600_400.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Lambda_Files/Step_txt_logs/f3.k16D6s2f64_3600_400.txt' does not exist: b'Lambda_Files/Step_txt_logs/f3.k16D6s2f64_3600_400.txt'"
     ]
    }
   ],
   "source": [
    "epoch_log = pd.read_csv('/Lambda_Files/Step_txt_logs/step_200_f3.k16D6s2f64_3600_200.txt', '-', names = my_cols, header=None).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63/63</td>\n",
       "      <td>122s</td>\n",
       "      <td>loss: 506.3037</td>\n",
       "      <td>sparse_categorical_accuracy: 0.4402</td>\n",
       "      <td>val_loss: 1.3232</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 1.1332</td>\n",
       "      <td>sparse_categorical_accuracy: 0.5634</td>\n",
       "      <td>val_loss: 1.3115</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.9677</td>\n",
       "      <td>sparse_categorical_accuracy: 0.6236</td>\n",
       "      <td>val_loss: 1.2923</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.8607</td>\n",
       "      <td>sparse_categorical_accuracy: 0.6683</td>\n",
       "      <td>val_loss: 1.0922</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.7485</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7115</td>\n",
       "      <td>val_loss: 1.0212</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.4799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.6570</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7480</td>\n",
       "      <td>val_loss: 0.9656</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.5812</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7766</td>\n",
       "      <td>val_loss: 1.0279</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.5229</td>\n",
       "      <td>sparse_categorical_accuracy: 0.7993</td>\n",
       "      <td>val_loss: 1.0471</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.4644</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8220</td>\n",
       "      <td>val_loss: 1.0424</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.4334</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8322</td>\n",
       "      <td>val_loss: 1.2364</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3793</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8537</td>\n",
       "      <td>val_loss: 1.1673</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3599</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8589</td>\n",
       "      <td>val_loss: 1.1352</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3508</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8635</td>\n",
       "      <td>val_loss: 1.1804</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3400</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8666</td>\n",
       "      <td>val_loss: 1.1189</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3226</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8744</td>\n",
       "      <td>val_loss: 1.0730</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3117</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8782</td>\n",
       "      <td>val_loss: 1.2335</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.3055</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8779</td>\n",
       "      <td>val_loss: 1.2702</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2882</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8860</td>\n",
       "      <td>val_loss: 1.0921</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2780</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8899</td>\n",
       "      <td>val_loss: 1.1386</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2731</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8910</td>\n",
       "      <td>val_loss: 1.1094</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>63/63</td>\n",
       "      <td>98s</td>\n",
       "      <td>loss: 0.2688</td>\n",
       "      <td>sparse_categorical_accuracy: 0.8926</td>\n",
       "      <td>val_loss: 1.0683</td>\n",
       "      <td>val_sparse_categorical_accuracy: 0.6801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1                 2                                      3  \\\n",
       "0   63/63    122s    loss: 506.3037    sparse_categorical_accuracy: 0.4402    \n",
       "1   63/63     98s      loss: 1.1332    sparse_categorical_accuracy: 0.5634    \n",
       "2   63/63     98s      loss: 0.9677    sparse_categorical_accuracy: 0.6236    \n",
       "3   63/63     98s      loss: 0.8607    sparse_categorical_accuracy: 0.6683    \n",
       "4   63/63     98s      loss: 0.7485    sparse_categorical_accuracy: 0.7115    \n",
       "5   63/63     98s      loss: 0.6570    sparse_categorical_accuracy: 0.7480    \n",
       "6   63/63     98s      loss: 0.5812    sparse_categorical_accuracy: 0.7766    \n",
       "7   63/63     98s      loss: 0.5229    sparse_categorical_accuracy: 0.7993    \n",
       "8   63/63     98s      loss: 0.4644    sparse_categorical_accuracy: 0.8220    \n",
       "9   63/63     98s      loss: 0.4334    sparse_categorical_accuracy: 0.8322    \n",
       "10  63/63     98s      loss: 0.3793    sparse_categorical_accuracy: 0.8537    \n",
       "11  63/63     98s      loss: 0.3599    sparse_categorical_accuracy: 0.8589    \n",
       "12  63/63     98s      loss: 0.3508    sparse_categorical_accuracy: 0.8635    \n",
       "13  63/63     98s      loss: 0.3400    sparse_categorical_accuracy: 0.8666    \n",
       "14  63/63     98s      loss: 0.3226    sparse_categorical_accuracy: 0.8744    \n",
       "15  63/63     98s      loss: 0.3117    sparse_categorical_accuracy: 0.8782    \n",
       "16  63/63     98s      loss: 0.3055    sparse_categorical_accuracy: 0.8779    \n",
       "17  63/63     98s      loss: 0.2882    sparse_categorical_accuracy: 0.8860    \n",
       "18  63/63     98s      loss: 0.2780    sparse_categorical_accuracy: 0.8899    \n",
       "19  63/63     98s      loss: 0.2731    sparse_categorical_accuracy: 0.8910    \n",
       "20  63/63     98s      loss: 0.2688    sparse_categorical_accuracy: 0.8926    \n",
       "\n",
       "                     4                                         5  \n",
       "0    val_loss: 1.3232    val_sparse_categorical_accuracy: 0.3848  \n",
       "1    val_loss: 1.3115    val_sparse_categorical_accuracy: 0.4083  \n",
       "2    val_loss: 1.2923    val_sparse_categorical_accuracy: 0.4314  \n",
       "3    val_loss: 1.0922    val_sparse_categorical_accuracy: 0.4688  \n",
       "4    val_loss: 1.0212    val_sparse_categorical_accuracy: 0.4799  \n",
       "5    val_loss: 0.9656    val_sparse_categorical_accuracy: 0.5354  \n",
       "6    val_loss: 1.0279    val_sparse_categorical_accuracy: 0.5225  \n",
       "7    val_loss: 1.0471    val_sparse_categorical_accuracy: 0.5793  \n",
       "8    val_loss: 1.0424    val_sparse_categorical_accuracy: 0.6113  \n",
       "9    val_loss: 1.2364    val_sparse_categorical_accuracy: 0.6192  \n",
       "10   val_loss: 1.1673    val_sparse_categorical_accuracy: 0.6339  \n",
       "11   val_loss: 1.1352    val_sparse_categorical_accuracy: 0.6430  \n",
       "12   val_loss: 1.1804    val_sparse_categorical_accuracy: 0.6523  \n",
       "13   val_loss: 1.1189    val_sparse_categorical_accuracy: 0.6442  \n",
       "14   val_loss: 1.0730    val_sparse_categorical_accuracy: 0.6647  \n",
       "15   val_loss: 1.2335    val_sparse_categorical_accuracy: 0.6635  \n",
       "16   val_loss: 1.2702    val_sparse_categorical_accuracy: 0.6728  \n",
       "17   val_loss: 1.0921    val_sparse_categorical_accuracy: 0.6757  \n",
       "18   val_loss: 1.1386    val_sparse_categorical_accuracy: 0.6890  \n",
       "19   val_loss: 1.1094    val_sparse_categorical_accuracy: 0.6947  \n",
       "20   val_loss: 1.0683    val_sparse_categorical_accuracy: 0.6801  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_log.dropna(axis=0).reset_index(drop = True)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_log = pd.read_csv('step_200_2/f3.k16D6s2f64_3600_200.txt', '-', names = my_cols, header=None).reset_index(drop = True)\n",
    "log_df = pd.DataFrame()\n",
    "log_len = len(epoch_log)\n",
    "#print(epoch_log)\n",
    "train_time = epoch_log['0'][log_len-15]\n",
    "#print(train_time)\n",
    "Pred_acc = epoch_log['0'][log_len-13]\n",
    "Pred_acc = Pred_acc\n",
    "#print(Pred_acc)\n",
    "C1 = epoch_log['0'][log_len-12]\n",
    "#print(C1)\n",
    "C2 = epoch_log['0'][log_len-11]\n",
    "#print(C2)\n",
    "C3 = epoch_log['0'][log_len-10]\n",
    "#print(C3)\n",
    "C4 = epoch_log['0'][log_len-9]\n",
    "#print(C4)\n",
    "epoch_log2 = epoch_log2.dropna(axis=0).reset_index(drop = True)#\n",
    "dropped_log_len = len(epoch_log2)\n",
    "#print(epoch_log2)\n",
    "log_ran = [*range(0, dropped_log_len, 1)]\n",
    "#d = defaultdict()\n",
    "d['Epoch Time'] = []\n",
    "d['Train Loss'] = []\n",
    "d['Train Acc'] = []\n",
    "d['Eval Loss'] = []\n",
    "d['Eval Acc'] = []\n",
    "for ro in log_ran:\n",
    "    \n",
    "    epoch_log_ro = epoch_log2.iloc[ro]\n",
    "    #epoch_log_ro['1']\n",
    "    #epoch_log_ro['2']\n",
    "    #epoch_log_ro['3']\n",
    "    #epoch_log_ro['4']\n",
    "    #epoch_log_ro['5']\n",
    "    epoch_time =re.split('[s\\s]', epoch_log_ro['1'])[1]\n",
    "    #rint(epoch_time)\n",
    "    loss =re.split('[loss:\\s]', epoch_log_ro['2'])[-2]\n",
    "    #print(loss)\n",
    "    acc = re.split('[sparse_categorical_accuracy:\\s]', epoch_log_ro['3'])[-2]\n",
    "    #print(acc)\n",
    "    eval_loss = re.split('[val_loss:\\s]', epoch_log_ro['4'])[-2]\n",
    "    #print(eval_loss)\n",
    "    eval_acc = re.split('val_sparse_categorical_accuracy: ', epoch_log_ro['5'])[1]\n",
    "    #print(eval_acc)\n",
    "\n",
    "    d['Epoch Time'].append(epoch_time)\n",
    "    d['Train Loss'].append(loss)\n",
    "    d['Train Acc'].append(acc)\n",
    "    d['Eval Loss'].append(eval_loss)\n",
    "    d['Eval Acc'].append(eval_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                      63/63 \n",
      "1                                       122s \n",
      "2                             loss: 506.3037 \n",
      "3        sparse_categorical_accuracy: 0.4402 \n",
      "4                           val_loss: 1.3232 \n",
      "5     val_sparse_categorical_accuracy: 0.3848\n",
      "Name: 0, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 1.1332 \n",
      "3        sparse_categorical_accuracy: 0.5634 \n",
      "4                           val_loss: 1.3115 \n",
      "5     val_sparse_categorical_accuracy: 0.4083\n",
      "Name: 1, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.9677 \n",
      "3        sparse_categorical_accuracy: 0.6236 \n",
      "4                           val_loss: 1.2923 \n",
      "5     val_sparse_categorical_accuracy: 0.4314\n",
      "Name: 2, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.8607 \n",
      "3        sparse_categorical_accuracy: 0.6683 \n",
      "4                           val_loss: 1.0922 \n",
      "5     val_sparse_categorical_accuracy: 0.4688\n",
      "Name: 3, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.7485 \n",
      "3        sparse_categorical_accuracy: 0.7115 \n",
      "4                           val_loss: 1.0212 \n",
      "5     val_sparse_categorical_accuracy: 0.4799\n",
      "Name: 4, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.6570 \n",
      "3        sparse_categorical_accuracy: 0.7480 \n",
      "4                           val_loss: 0.9656 \n",
      "5     val_sparse_categorical_accuracy: 0.5354\n",
      "Name: 5, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.5812 \n",
      "3        sparse_categorical_accuracy: 0.7766 \n",
      "4                           val_loss: 1.0279 \n",
      "5     val_sparse_categorical_accuracy: 0.5225\n",
      "Name: 6, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.5229 \n",
      "3        sparse_categorical_accuracy: 0.7993 \n",
      "4                           val_loss: 1.0471 \n",
      "5     val_sparse_categorical_accuracy: 0.5793\n",
      "Name: 7, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.4644 \n",
      "3        sparse_categorical_accuracy: 0.8220 \n",
      "4                           val_loss: 1.0424 \n",
      "5     val_sparse_categorical_accuracy: 0.6113\n",
      "Name: 8, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.4334 \n",
      "3        sparse_categorical_accuracy: 0.8322 \n",
      "4                           val_loss: 1.2364 \n",
      "5     val_sparse_categorical_accuracy: 0.6192\n",
      "Name: 9, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3793 \n",
      "3        sparse_categorical_accuracy: 0.8537 \n",
      "4                           val_loss: 1.1673 \n",
      "5     val_sparse_categorical_accuracy: 0.6339\n",
      "Name: 10, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3599 \n",
      "3        sparse_categorical_accuracy: 0.8589 \n",
      "4                           val_loss: 1.1352 \n",
      "5     val_sparse_categorical_accuracy: 0.6430\n",
      "Name: 11, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3508 \n",
      "3        sparse_categorical_accuracy: 0.8635 \n",
      "4                           val_loss: 1.1804 \n",
      "5     val_sparse_categorical_accuracy: 0.6523\n",
      "Name: 12, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3400 \n",
      "3        sparse_categorical_accuracy: 0.8666 \n",
      "4                           val_loss: 1.1189 \n",
      "5     val_sparse_categorical_accuracy: 0.6442\n",
      "Name: 13, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3226 \n",
      "3        sparse_categorical_accuracy: 0.8744 \n",
      "4                           val_loss: 1.0730 \n",
      "5     val_sparse_categorical_accuracy: 0.6647\n",
      "Name: 14, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3117 \n",
      "3        sparse_categorical_accuracy: 0.8782 \n",
      "4                           val_loss: 1.2335 \n",
      "5     val_sparse_categorical_accuracy: 0.6635\n",
      "Name: 15, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.3055 \n",
      "3        sparse_categorical_accuracy: 0.8779 \n",
      "4                           val_loss: 1.2702 \n",
      "5     val_sparse_categorical_accuracy: 0.6728\n",
      "Name: 16, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.2882 \n",
      "3        sparse_categorical_accuracy: 0.8860 \n",
      "4                           val_loss: 1.0921 \n",
      "5     val_sparse_categorical_accuracy: 0.6757\n",
      "Name: 17, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.2780 \n",
      "3        sparse_categorical_accuracy: 0.8899 \n",
      "4                           val_loss: 1.1386 \n",
      "5     val_sparse_categorical_accuracy: 0.6890\n",
      "Name: 18, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.2731 \n",
      "3        sparse_categorical_accuracy: 0.8910 \n",
      "4                           val_loss: 1.1094 \n",
      "5     val_sparse_categorical_accuracy: 0.6947\n",
      "Name: 19, dtype: object\n",
      "0                                      63/63 \n",
      "1                                        98s \n",
      "2                               loss: 0.2688 \n",
      "3        sparse_categorical_accuracy: 0.8926 \n",
      "4                           val_loss: 1.0683 \n",
      "5     val_sparse_categorical_accuracy: 0.6801\n",
      "Name: 20, dtype: object\n"
     ]
    }
   ],
   "source": [
    "log_ran = [*range(0, dropped_log_len, 1)]\n",
    "d = dict()\n",
    "for ro in log_ran:\n",
    "    \n",
    "    epoch_log_ro = epoch_log2.iloc[ro]\n",
    "    print(epoch_log_ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['122',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98',\n",
       " '98']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['Epoch Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step_100.read_csv(r'{}.csv'.format('List_Check_100'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])\n",
    "Step_200.read_csv(r'{}.csv'.format('List_Check_200'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])\n",
    "Step_300.read_csv(r'{}.csv'.format('List_Check_300'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])\n",
    "Step_400.read_csv(r'{}.csv'.format('List_Check_400'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])\n",
    "Step_500.read_csv(r'{}.csv'.format('List_Check_500'), index = False, header=['segment length', 'filters', 'kernel size', 'stacks', 'dropout', 'lr', 'dilation','Training Time', 'train loss', 'train acc', 'eval acc','Eval Acc','C1 correct', 'C1 as C2', 'C1 as C3', 'C1 as C4','C2 as C1', 'C2 correct', 'C2 as C3', 'C2 as C4','C3 as C1', 'C3 as C2', 'C3 correct', 'C3 as C4','C4 as C1', 'C4 as C2', 'C4 as C3', 'C4 correct'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
