{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tcn in /usr/local/lib/python3.7/site-packages (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow-addons[tensorflow-gpu] in /usr/local/lib/python3.7/site-packages (0.12.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: multivariate_cwru in /usr/local/lib/python3.7/site-packages (0.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (4.60.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from scipy) (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from sklearn) (0.23.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/site-packages (2.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "%pip install keras-tcn --no-dependencies\n",
    "\n",
    "%pip install tensorflow-addons[tensorflow-gpu] --no-dependencies\n",
    "\n",
    "%pip install pandas --upgrade\n",
    "\n",
    "%pip install multivariate_cwru\n",
    "\n",
    "%pip install tqdm\n",
    "\n",
    "%pip install scipy\n",
    "\n",
    "%pip install sklearn\n",
    "\n",
    "%pip install matplotlib\n",
    "\n",
    "%pip install typeguard\n",
    "\n",
    "\n",
    "tf.config.list_physical_devices(device_type=None)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "print(visible_devices)\n",
    "num_GPU = len(tf.config.experimental.list_physical_devices('/physical_device:GPU:0'))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "#Deep Learning pkgs\n",
    "from tensorflow.keras import backend as K, Input, Model, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import tensorflow.keras.metrics\n",
    "from tensorflow.keras.metrics import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint, Callback\n",
    "from tensorflow.keras.activations import swish\n",
    "K.backend()\n",
    "\n",
    "# Python\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "#Project Specific\n",
    "import tcn_ed\n",
    "from tcn_ed import TCN, tcn_full_summary, compiled_tcn\n",
    "from help_pre import create_data_batcht as Create_Batch, create_pred_batch\n",
    "import multivariate_cwru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_import(dir_p, use_type, high_freq = False, b_size=1024):\n",
    "    segment_length = 2400\n",
    "    target = 'label'\n",
    "    cwd = os.getcwd()\n",
    "    col_ran = [*range(2400)]\n",
    "    d_t = dict()\n",
    "    d_t['label'] = 'int8'\n",
    "    d_t['Unnamed: 0'] = 'int8'\n",
    "    for col in col_ran:\n",
    "        d_t['%s' % col] =  'float16'\n",
    "    \n",
    "    if str(cwd) == str(dir_p):\n",
    "        dir_path=Path('./')\n",
    "    else: dir_path = dir_p\n",
    "    \n",
    "    if use_type == 'train':\n",
    "        if high_freq == False:\n",
    "            train_frame = pd.read_csv((r'{}.csv').format('train_df_no48'), dtype=(d_t))\n",
    "            test_frame = pd.read_csv((r'{}.csv').format('test_df_no48'), dtype=(d_t))\n",
    "            \n",
    "        if high_freq:\n",
    "            train_frame = pd.read_csv((r'{}.csv').format('train_df_w48'), dtype=(d_t))\n",
    "            test_frame = pd.read_csv((r'{}.csv').format('test_df_w48'), dtype=(d_t))\n",
    "            \n",
    "        train_frame = train_frame.set_index(train_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "        train_target = train_frame.pop('label')\n",
    "        train_x = train_frame.to_numpy().reshape(len(train_frame), segment_length, 1)\n",
    "        train_y = train_target.to_numpy().reshape(-1, 1)\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.apply_default_optimizations = True\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(b_size).with_options(options).cache()\n",
    "        test_frame = test_frame.set_index(test_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "        test_target = test_frame.pop('label')\n",
    "        test_x = test_frame.to_numpy().reshape(len(test_frame), segment_length, 1)\n",
    "        test_y = test_target.to_numpy().reshape(-1, 1)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(b_size).with_options(options).cache()\n",
    "        print('class balance of train frame: %s' % train_target.value_counts())\n",
    "        print('class balance of validation (test) frame: %s' % test_target.value_counts())\n",
    "        out_1 = train_dataset\n",
    "        out_2 = test_dataset\n",
    "            \n",
    "    if use_type == 'pred':\n",
    "        if high_freq == False:\n",
    "            val_frame = pd.read_csv((r'{}.csv').format('pred_df_no48'), dtype=d_t)\n",
    "            \n",
    "        if high_freq:\n",
    "            val_frame == pd.read_csv((r'{}.csv').format('pred_df_w48'), dtype=d_t)\n",
    "\n",
    "\n",
    "        val_frame = val_frame.set_index(val_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "        val_target = val_frame.pop('label')\n",
    "        print('class balance of train frame: %s' % val_target.value_counts())\n",
    "        val_x = val_frame.to_numpy().reshape(len(val_frame), segment_length, 1)\n",
    "        val_y = val_target.to_numpy().reshape(-1, 1)\n",
    "\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.apply_default_optimizations = True\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(b_size).with_options(options).cache()\n",
    "\n",
    "        out_1 = dataset\n",
    "        out_2 = val_y\n",
    "        \n",
    "    return out_1, out_2\n",
    "\n",
    "def adjust_dilations(dilations: list):\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        return new_dilations\n",
    "        \n",
    "def pred_accuracy(y_true, y_pred):\n",
    "            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "            # convert dense predictions to labels\n",
    "            y_pred_labels = K.cast(y_pred, K.floatx())\n",
    "            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n",
    "\n",
    "def create_model(num_feat,\n",
    "                 num_classes,\n",
    "                 filt_num,\n",
    "                 kernel_num,\n",
    "                 stack, dilation,\n",
    "                 lr,\n",
    "                 drop_rate,\n",
    "                 segment_length,\n",
    "                 use_skip,\n",
    "                 opt):\n",
    "\n",
    "    #with mirrored_strategy.scope():\n",
    "\n",
    "    input_layer = Input(shape=(segment_length, num_feat))\n",
    "\n",
    "    def get_opt():\n",
    "        if opt == 'adam':\n",
    "            return optimizers.Adam(lr=lr)\n",
    "        elif opt == 'rmsprop':\n",
    "            return optimizers.RMSprop(lr=lr)\n",
    "        else:\n",
    "            raise Exception('Only Adam and RMSProp are available here')\n",
    "\n",
    "    x = TCN(nb_filters=filt_num,\n",
    "            kernel_size=kernel_num,\n",
    "            nb_stacks=stack,\n",
    "            dilations=[2 ** i for i in range(dilation)],\n",
    "            padding='causal',\n",
    "            use_skip_connections=use_skip,\n",
    "            dropout_rate=drop_rate,\n",
    "            return_sequences=False,\n",
    "            activation='swish', \n",
    "            kernel_initializer='he_uniform',\n",
    "            use_batch_norm=False,\n",
    "            use_layer_norm=False,\n",
    "            use_weight_norm=True,\n",
    "            name='Model')(input_layer)\n",
    "\n",
    "    tcn = TCN(nb_filters=filt_num,\n",
    "              kernel_size=kernel_num,\n",
    "              nb_stacks=stack,\n",
    "              dilations=[2 ** i for i in range(dilation)],\n",
    "              padding='causal',\n",
    "              use_skip_connections=use_skip,\n",
    "              dropout_rate=drop_rate,\n",
    "              return_sequences=False,\n",
    "              activation='swish', \n",
    "              kernel_initializer='he_uniform',\n",
    "              use_batch_norm=False,\n",
    "              use_layer_norm=False,\n",
    "              use_weight_norm=True,\n",
    "              name='Model')\n",
    "\n",
    "    print('Receptive Field Size: %s' % tcn.receptive_field)\n",
    "\n",
    "\n",
    "\n",
    "    print('x.shape=', x.shape)\n",
    "\n",
    "\n",
    "    # classification\n",
    "    x = Dense(num_classes)(x)\n",
    "    x = Activation('softmax', dtype='float32')(x)\n",
    "    output_layer = x\n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    # https://github.com/keras-team/keras/pull/11373\n",
    "    # It's now in Keras@master but still not available with pip.\n",
    "    # TODO remove later.\n",
    "\n",
    "    #with mirrored_strategy.scope():\n",
    "    model.compile(get_opt(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    print('model.x = {}'.format(input_layer.shape))\n",
    "    print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "    print('Filter Length: %s' % filt_num)\n",
    "    print('Kernel Size: %s' % kernel_num)\n",
    "    print('Dilation: %s' % dilation)\n",
    "    print('Learning Rate: %s' % lr)\n",
    "    print('Dropout Rate: %s' % drop_rate)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_func(train_data,\n",
    "               test_dataset,\n",
    "               Val_dataset,\n",
    "               predict_labels,\n",
    "               segment_length,\n",
    "               runs,\n",
    "               filt_num,\n",
    "               kernel_num,\n",
    "               dilation,\n",
    "               stack,\n",
    "               learn_r,\n",
    "               drop_rate,\n",
    "               Model_num,\n",
    "               callback):\n",
    "    \n",
    "    \n",
    "        \n",
    "    time1 = timer()\n",
    "        \n",
    "    working_dir = Path('.')\n",
    "    model_path = working_dir / 'Model' / ('Model_{}_k{}_s{}_di{}_dr{}_L{}'.format(Model_num, kernel_num, stack, dilation, drop_rate, segment_length))\n",
    "    \n",
    "    time_out = timer()-time1\n",
    "    print('Time till start of create model %s' % time_out)\n",
    "    time2 = timer()\n",
    "    model = create_model(num_feat=1,\n",
    "                         num_classes=4,\n",
    "                         filt_num=filt_num,\n",
    "                         kernel_num=kernel_num,\n",
    "                         stack=stack,\n",
    "                         dilation=dilation,\n",
    "                         lr=learn_r,\n",
    "                         drop_rate=drop_rate,\n",
    "                         segment_length = segment_length,\n",
    "                         use_skip=True,\n",
    "                         opt='adam')\n",
    "\n",
    "    time3 = timer()\n",
    "    time_out = time3-time2\n",
    "    print('Time to create model %s' % time_out)\n",
    "    #with mirrored_strategy.scope():\n",
    "    history = model.fit(train_data,\n",
    "              epochs=runs,\n",
    "              verbose=1,\n",
    "              callbacks=callback,\n",
    "              validation_data=test_dataset)\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    time_out = timer()-time3\n",
    "    print('Time to fit model %s' % time_out)\n",
    "    #with mirrored_strategy.scope():\n",
    "    y_preds = model.predict(Val_dataset,\n",
    "                                   verbose=1,\n",
    "                                   callbacks=callback,\n",
    "                                  )\n",
    "    y_argmax2 = np.argmax(y_preds,axis=1)\n",
    "    predict_labels = np.squeeze(predict_labels[:], axis=1)\n",
    "    #for pred1, pred2, pred3, pred4 in y_pred:\n",
    "    #y_argmax = []\n",
    "    #i=0\n",
    "    perc_score = tf.dtypes.cast((sum(pred_accuracy(predict_labels, y_argmax2))/(len(predict_labels))), tf.float16)\n",
    "    Accuracy_test = float(perc_score)\n",
    "    print('Prediction Accuracy: %s' % Accuracy_test)\n",
    "    con_mat = metrics.confusion_matrix(predict_labels, y_argmax2)\n",
    "    class_report = metrics.classification_report(predict_labels, y_argmax2, digits=3)\n",
    "    print(con_mat, '\\n\\n')\n",
    "    print(class_report, '\\n\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    d = {'segment length':[segment_length], 'filters': [filt_num], 'kernel size': [kernel_num], 'stacks':[stack], 'dropout': [drop_rate], 'lr': [learn_r], 'dilation': [dilation], 'Training Time': time_out, 'train loss': [history.history['loss'][-1]], 'train acc': [history.history['sparse_categorical_accuracy'][-1]], 'eval acc': [history.history['val_sparse_categorical_accuracy'][-1]], 'Eval Acc': [Accuracy_test],'C1 correct': [con_mat[0][0]], 'C1 as C2':[con_mat[0][1]], 'C1 as C3':[con_mat[0][2]], 'C1 as C4':[con_mat[0][3]],'C2 as C1': [con_mat[1][0]], 'C2 correct':[con_mat[1][1]], 'C2 as C3':[con_mat[1][2]], 'C2 as C4':[con_mat[1][3]],'C3 as C1': [con_mat[2][0]], 'C3 as C2':[con_mat[2][1]], 'C3 correct':[con_mat[2][2]], 'C3 as C4':[con_mat[2][3]],'C4 as C1': [con_mat[3][0]], 'C4 as C2':[con_mat[3][1]], 'C4 as C3':[con_mat[3][2]], 'C4 correct':[con_mat[3][3]]}\n",
    "    \n",
    "    \n",
    "    append_list2_in = pd.DataFrame.from_dict(d)\n",
    "    \n",
    "    time_out = timer()-time1\n",
    "    print('Total Time %s' % time_out)\n",
    "    \n",
    "    return model, history, y_preds, append_list2_in\n",
    "\n",
    "def create_model2(num_feat,\n",
    "                 num_classes,\n",
    "                 filt_num,\n",
    "                 kernel_num,\n",
    "                 stack, dilation,\n",
    "                 lr,\n",
    "                 drop_rate,\n",
    "                 segment_length,\n",
    "                 use_skip,\n",
    "                 opt):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #with mirrored_strategy.scope():\n",
    "    #x =Sequential()\n",
    "\n",
    "\n",
    "    input_layer = Input(shape=(segment_length, num_feat))\n",
    "\n",
    "    def get_opt():\n",
    "        if opt == 'adam':\n",
    "            return optimizers.Adam(lr=lr)\n",
    "        elif opt == 'rmsprop':\n",
    "            return optimizers.RMSprop(lr=lr)\n",
    "        else:\n",
    "            raise Exception('Only Adam and RMSProp are available here')\n",
    "\n",
    "    x = TCN(nb_filters=filt_num,\n",
    "            kernel_size=kernel_num,\n",
    "            nb_stacks=stack,\n",
    "            dilations=[2 ** i for i in range(dilation)],\n",
    "            padding='causal',\n",
    "            use_skip_connections=use_skip,\n",
    "            dropout_rate=drop_rate,\n",
    "            return_sequences=False,\n",
    "            activation='swish', \n",
    "            kernel_initializer='he_uniform',\n",
    "            use_batch_norm=True,\n",
    "            use_layer_norm=False,\n",
    "            use_weight_norm=False,\n",
    "            name='Model')(input_layer)\n",
    "\n",
    "    tcn = TCN(nb_filters=filt_num,\n",
    "              kernel_size=kernel_num,\n",
    "              nb_stacks=stack,\n",
    "              dilations=[2 ** i for i in range(dilation)],\n",
    "              padding='causal',\n",
    "              use_skip_connections=use_skip,\n",
    "              dropout_rate=drop_rate,\n",
    "              return_sequences=False,\n",
    "              activation='swish', \n",
    "              kernel_initializer='he_uniform',\n",
    "              use_batch_norm=True,\n",
    "              use_layer_norm=False,\n",
    "              use_weight_norm=False,\n",
    "              name='Model')\n",
    "\n",
    "    print('Receptive Field Size: %s' % tcn.receptive_field)\n",
    "\n",
    "\n",
    "\n",
    "    print('x.shape=', x.shape)\n",
    "\n",
    "\n",
    "    # classification\n",
    "    x = Dense(num_classes)(x)\n",
    "    x = Activation('softmax', dtype='float32')(x)\n",
    "    output_layer = x\n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    # https://github.com/keras-team/keras/pull/11373\n",
    "    # It's now in Keras@master but still not available with pip.\n",
    "    # TODO remove later.\n",
    "\n",
    "    #with mirrored_strategy.scope():\n",
    "    model.compile(get_opt(), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    print('model.x = {}'.format(input_layer.shape))\n",
    "    print('model.y = {}'.format(output_layer.shape))\n",
    "\n",
    "    print('Filter Length: %s' % filt_num)\n",
    "    print('Kernel Size: %s' % kernel_num)\n",
    "    print('Dilation: %s' % dilation)\n",
    "    print('Learning Rate: %s' % lr)\n",
    "    print('Dropout Rate: %s' % drop_rate)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_func2(train_data,\n",
    "               test_dataset,\n",
    "               Val_dataset,\n",
    "               predict_labels,\n",
    "               segment_length,\n",
    "               runs,\n",
    "               filt_num,\n",
    "               kernel_num,\n",
    "               dilation,\n",
    "               stack,\n",
    "               learn_r,\n",
    "               drop_rate,\n",
    "               Model_num,\n",
    "               callback):\n",
    "    \n",
    "    \n",
    "        \n",
    "    time1 = timer()\n",
    "        \n",
    "    working_dir = Path('.')\n",
    "    model_path = working_dir / 'Model' / ('Model_{}_k{}_s{}_di{}_dr{}_L{}.H5'.format(Model_num, kernel_num, stack, dilation, drop_rate, segment_length))\n",
    "    \n",
    "    \n",
    "\n",
    "    #seg_length = None\n",
    "    time_out = timer()-time1\n",
    "    print('Time till start of create model %s' % time_out)\n",
    "    time2 = timer()\n",
    "    model = create_model2(num_feat=1,\n",
    "                         num_classes=4,\n",
    "                         filt_num=filt_num,\n",
    "                         kernel_num=kernel_num,\n",
    "                         stack=stack,\n",
    "                         dilation=dilation,\n",
    "                         lr=learn_r,\n",
    "                         drop_rate=drop_rate,\n",
    "                         segment_length = segment_length,\n",
    "                         use_skip=True,\n",
    "                         opt='adam')\n",
    "\n",
    "    time3 = timer()\n",
    "    time_out = time3-time2\n",
    "    print('Time to create model %s' % time_out)\n",
    "    #with mirrored_strategy.scope():\n",
    "    history = model.fit(train_data,\n",
    "              epochs=runs,\n",
    "              verbose=1,\n",
    "              callbacks=callback,\n",
    "              validation_data=test_dataset,\n",
    "              use_multiprocessing=True)\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    time_out = timer()-time3\n",
    "    print('Time to fit model %s' % time_out)\n",
    "    #with mirrored_strategy.scope():\n",
    "    y_preds = model.predict(Val_dataset,\n",
    "                                   verbose=1,\n",
    "                                   callbacks=callback,\n",
    "                                  )\n",
    "    y_argmax2 = np.argmax(y_preds,axis=1)\n",
    "    predict_labels = np.squeeze(predict_labels[:], axis=1)\n",
    "    #for pred1, pred2, pred3, pred4 in y_pred:\n",
    "    #y_argmax = []\n",
    "    #i=0\n",
    "    perc_score = tf.dtypes.cast((sum(pred_accuracy(predict_labels, y_argmax2))/(len(predict_labels))), tf.float16)\n",
    "    Accuracy_test = float(perc_score)\n",
    "    print('Prediction Accuracy: %s' % Accuracy_test)\n",
    "    con_mat = metrics.confusion_matrix(predict_labels, y_argmax2)\n",
    "    class_report = metrics.classification_report(predict_labels, y_argmax2, digits=3)\n",
    "    print(con_mat, '\\n\\n')\n",
    "    print(class_report, '\\n\\n')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    d = {'segment length':[segment_length], 'filters': [filt_num], 'kernel size': [kernel_num], 'stacks':[stack], 'dropout': [drop_rate], 'lr': [learn_r], 'dilation': [dilation], 'Training Time': time_out, 'train loss': [history.history['loss'][-1]], 'train acc': [history.history['sparse_categorical_accuracy'][-1]], 'eval acc': [history.history['val_sparse_categorical_accuracy'][-1]], 'Eval Acc': [Accuracy_test],'C1 correct': [con_mat[0][0]], 'C1 as C2':[con_mat[0][1]], 'C1 as C3':[con_mat[0][2]], 'C1 as C4':[con_mat[0][3]],'C2 as C1': [con_mat[1][0]], 'C2 correct':[con_mat[1][1]], 'C2 as C3':[con_mat[1][2]], 'C2 as C4':[con_mat[1][3]],'C3 as C1': [con_mat[2][0]], 'C3 as C2':[con_mat[2][1]], 'C3 correct':[con_mat[2][2]], 'C3 as C4':[con_mat[2][3]],'C4 as C1': [con_mat[3][0]], 'C4 as C2':[con_mat[3][1]], 'C4 as C3':[con_mat[3][2]], 'C4 correct':[con_mat[3][3]]}\n",
    "    \n",
    "    \n",
    "    append_list2_in = pd.DataFrame.from_dict(d)\n",
    "       \n",
    "    time_out = timer()-time1\n",
    "    print('Total Time %s' % time_out)\n",
    "    \n",
    "    return model, history, y_preds, append_list2_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ran = [*range(2400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance of train frame: 3    57451\n",
      "1    28917\n",
      "2    28747\n",
      "0     9656\n",
      "Name: label, dtype: int64\n",
      "class balance of validation (test) frame: 3    30229\n",
      "1    12081\n",
      "2    11013\n",
      "0     9650\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = csv_import(dir_p = os.getcwd(), use_type='train', high_freq = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance of train frame: 3    4770\n",
      "1    2384\n",
      "2    2384\n",
      "0    1612\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_dataset, predict_labels = csv_import(dir_p = os.getcwd(), use_type = 'pred' , high_freq = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.5,   \n",
    "                              patience=3, \n",
    "                              min_lr=0.000000015,\n",
    "                              verbose=1, \n",
    "                              cooldown=5)\n",
    "\n",
    "ES_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                         min_delta=0.00001, \n",
    "                                         patience=25, \n",
    "                                         verbose=0, \n",
    "                                         mode='auto', \n",
    "                                         baseline=None, \n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "callback = [reduce_lr, ES_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1024 #normally 2048 but 512 on colab\n",
    "step_size = 300\n",
    "step_length=step_size\n",
    "segment_length = 2400\n",
    "split_perc = 0.3\n",
    "working_dir = Path('.')\n",
    "DATA_PATH = Path(\"./Datatest/CWRU\")\n",
    "save_model_path = working_dir / 'Model' \n",
    "\n",
    "for path in [DATA_PATH, save_model_path]:\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_list_time1=pd.DataFrame()\n",
    "Learning_Rate = 0.02\n",
    "Drop_rate = 0\n",
    "Repeats = 75\n",
    "m_count=1\n",
    "print('Model Number %s' % m_count)\n",
    "model1, history1, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=4,\n",
    "                                        kernel_num=8,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance of train frame: 3    57451\n",
      "1    28917\n",
      "2    28747\n",
      "0     9656\n",
      "Name: label, dtype: int64\n",
      "class balance of validation (test) frame: 3    30229\n",
      "1    12081\n",
      "2    11013\n",
      "0     9650\n",
      "Name: label, dtype: int64\n",
      "class balance of train frame: 3    4770\n",
      "2    2384\n",
      "1    2384\n",
      "0    1612\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "segment_length = 2400\n",
    "target = 'label'\n",
    "cwd = os.getcwd()\n",
    "col_ran = [*range(2400)]\n",
    "b_size = 512\n",
    "d_t = dict()\n",
    "d_t['label'] = 'int8'\n",
    "d_t['Unnamed: 0'] = 'int8'\n",
    "for col in col_ran:\n",
    "    d_t['%s' % col] =  'float32'\n",
    "\n",
    "\n",
    "\n",
    "train_frame = pd.read_csv((r'{}.csv').format('train_df_w48'), dtype=(d_t))\n",
    "test_frame = pd.read_csv((r'{}.csv').format('test_df_w48'), dtype=(d_t))\n",
    "\n",
    "train_frame = train_frame.set_index(train_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "train_target = train_frame.pop('label')\n",
    "train_x = train_frame.to_numpy().reshape(len(train_frame), segment_length, 1)\n",
    "train_y = train_target.to_numpy().reshape(-1, 1)\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(b_size).with_options(options).cache()\n",
    "test_frame = test_frame.set_index(test_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "test_target = test_frame.pop('label')\n",
    "test_x = test_frame.to_numpy().reshape(len(test_frame), segment_length, 1)\n",
    "test_y = test_target.to_numpy().reshape(-1, 1)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(b_size).with_options(options).cache()\n",
    "print('class balance of train frame: %s' % train_target.value_counts())\n",
    "print('class balance of validation (test) frame: %s' % test_target.value_counts())\n",
    "out_1 = train_dataset\n",
    "out_2 = test_dataset\n",
    "\n",
    "val_frame = pd.read_csv((r'{}.csv').format('pred_df_no48'), dtype=d_t)\n",
    "\n",
    "\n",
    "val_frame = val_frame.set_index(val_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "val_target = val_frame.pop('label')\n",
    "print('class balance of train frame: %s' % val_target.value_counts())\n",
    "val_x = val_frame.to_numpy().reshape(len(val_frame), segment_length, 1)\n",
    "val_y = val_target.to_numpy().reshape(-1, 1)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(b_size).with_options(options).cache()\n",
    "\n",
    "val_dataset = dataset\n",
    "out_2 = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.3,   \n",
    "                              patience=10, \n",
    "                              min_lr=0.0000000015,\n",
    "                              verbose=0, \n",
    "                              cooldown=5)\n",
    "\n",
    "ES_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                         min_delta=0.00001, \n",
    "                                         patience=25, \n",
    "                                         verbose=0, \n",
    "                                         mode='auto', \n",
    "                                         baseline=None, \n",
    "                                         restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "callback = [reduce_lr, ES_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number 1\n",
      "Time till start of create model 4.165699647273868e-05\n",
      "[2021-05-12 05:44:21.076 tensorflow-2-3-gpu-ml-g4dn-4xlarge-f1d995902f6ec07d1f4d0a5fa443:4722 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-05-12 05:44:21.100 tensorflow-2-3-gpu-ml-g4dn-4xlarge-f1d995902f6ec07d1f4d0a5fa443:4722 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Receptive Field Size: 2541\n",
      "x.shape= (None, 8)\n",
      "model.x = (None, 2400, 1)\n",
      "model.y = (None, 4)\n",
      "Filter Length: 8\n",
      "Kernel Size: 11\n",
      "Dilation: 7\n",
      "Learning Rate: 0.02\n",
      "Dropout Rate: 0\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2400, 1)]         0         \n",
      "_________________________________________________________________\n",
      "Model (TCN)                  (None, 8)                 9816      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 9,852\n",
      "Trainable params: 9,628\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Time to create model 1.544660188999842\n",
      "Epoch 1/75\n",
      "122/122 [==============================] - 107s 875ms/step - loss: 0.8089 - sparse_categorical_accuracy: 0.6225 - val_loss: 86.7096 - val_sparse_categorical_accuracy: 0.4765\n",
      "Epoch 2/75\n",
      "122/122 [==============================] - 104s 855ms/step - loss: 0.3418 - sparse_categorical_accuracy: 0.8506 - val_loss: 12.6647 - val_sparse_categorical_accuracy: 0.4807\n",
      "Epoch 3/75\n",
      "122/122 [==============================] - 103s 847ms/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9469 - val_loss: 12.0627 - val_sparse_categorical_accuracy: 0.5004\n",
      "Epoch 4/75\n",
      "122/122 [==============================] - 104s 853ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9822 - val_loss: 5.9207 - val_sparse_categorical_accuracy: 0.5219\n",
      "Epoch 5/75\n",
      "122/122 [==============================] - 104s 856ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9883 - val_loss: 6.2144 - val_sparse_categorical_accuracy: 0.5321\n",
      "Epoch 6/75\n",
      "122/122 [==============================] - 103s 848ms/step - loss: 0.0255 - sparse_categorical_accuracy: 0.9915 - val_loss: 6.5016 - val_sparse_categorical_accuracy: 0.5522\n",
      "Epoch 7/75\n",
      "122/122 [==============================] - 104s 855ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9939 - val_loss: 5.3560 - val_sparse_categorical_accuracy: 0.6125\n",
      "Epoch 8/75\n",
      "122/122 [==============================] - 104s 854ms/step - loss: 0.0248 - sparse_categorical_accuracy: 0.9915 - val_loss: 3.1106 - val_sparse_categorical_accuracy: 0.6468\n",
      "Epoch 9/75\n",
      "122/122 [==============================] - 103s 846ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972 - val_loss: 3.9307 - val_sparse_categorical_accuracy: 0.6888\n",
      "Epoch 10/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978 - val_loss: 3.8830 - val_sparse_categorical_accuracy: 0.6821\n",
      "Epoch 11/75\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0225 - sparse_categorical_accuracy: 0.9931\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9931 - val_loss: 5.2043 - val_sparse_categorical_accuracy: 0.6253\n",
      "Epoch 12/75\n",
      "122/122 [==============================] - 103s 848ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987 - val_loss: 2.5620 - val_sparse_categorical_accuracy: 0.7150\n",
      "Epoch 13/75\n",
      "122/122 [==============================] - 105s 859ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9992 - val_loss: 2.4309 - val_sparse_categorical_accuracy: 0.7386\n",
      "Epoch 14/75\n",
      "122/122 [==============================] - 103s 848ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9993 - val_loss: 3.0137 - val_sparse_categorical_accuracy: 0.6759\n",
      "Epoch 15/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9994 - val_loss: 2.9844 - val_sparse_categorical_accuracy: 0.7273\n",
      "Epoch 16/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9993 - val_loss: 3.3505 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 17/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9988 - val_loss: 6.9600 - val_sparse_categorical_accuracy: 0.6143\n",
      "Epoch 18/75\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.0021 - sparse_categorical_accuracy: 0.9993\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "122/122 [==============================] - 104s 850ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9993 - val_loss: 3.2407 - val_sparse_categorical_accuracy: 0.7194\n",
      "Epoch 19/75\n",
      "122/122 [==============================] - 105s 858ms/step - loss: 6.2896e-04 - sparse_categorical_accuracy: 0.9998 - val_loss: 3.0585 - val_sparse_categorical_accuracy: 0.7361\n",
      "Epoch 20/75\n",
      "122/122 [==============================] - 103s 848ms/step - loss: 3.3574e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 2.9743 - val_sparse_categorical_accuracy: 0.7420\n",
      "Epoch 21/75\n",
      "122/122 [==============================] - 104s 851ms/step - loss: 1.9114e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0630 - val_sparse_categorical_accuracy: 0.7422\n",
      "Epoch 22/75\n",
      "122/122 [==============================] - 105s 857ms/step - loss: 1.5273e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.0709 - val_sparse_categorical_accuracy: 0.7439\n",
      "Epoch 23/75\n",
      "122/122 [==============================] - 103s 847ms/step - loss: 1.2747e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1097 - val_sparse_categorical_accuracy: 0.7449\n",
      "Epoch 24/75\n",
      "122/122 [==============================] - 104s 852ms/step - loss: 1.1067e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1224 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 25/75\n",
      "122/122 [==============================] - ETA: 0s - loss: 9.7756e-05 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "122/122 [==============================] - 104s 856ms/step - loss: 9.7756e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1245 - val_sparse_categorical_accuracy: 0.7456\n",
      "Epoch 26/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 8.4028e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1666 - val_sparse_categorical_accuracy: 0.7456\n",
      "Epoch 27/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 7.8604e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.1776 - val_sparse_categorical_accuracy: 0.7453\n",
      "Epoch 28/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 7.3739e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2143 - val_sparse_categorical_accuracy: 0.7451\n",
      "Epoch 29/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 6.9343e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2426 - val_sparse_categorical_accuracy: 0.7449\n",
      "Epoch 30/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 6.5336e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2486 - val_sparse_categorical_accuracy: 0.7449\n",
      "Epoch 31/75\n",
      "122/122 [==============================] - 103s 845ms/step - loss: 6.1615e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2677 - val_sparse_categorical_accuracy: 0.7448\n",
      "Epoch 32/75\n",
      "122/122 [==============================] - ETA: 0s - loss: 5.8130e-05 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "122/122 [==============================] - 103s 847ms/step - loss: 5.8130e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2920 - val_sparse_categorical_accuracy: 0.7447\n",
      "Epoch 33/75\n",
      "122/122 [==============================] - 105s 857ms/step - loss: 5.4901e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3839 - val_sparse_categorical_accuracy: 0.7435\n",
      "Epoch 34/75\n",
      "122/122 [==============================] - 104s 849ms/step - loss: 5.1810e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3931 - val_sparse_categorical_accuracy: 0.7434\n",
      "Epoch 35/75\n",
      "122/122 [==============================] - 104s 849ms/step - loss: 5.0072e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3961 - val_sparse_categorical_accuracy: 0.7437\n",
      "Epoch 36/75\n",
      "122/122 [==============================] - 105s 859ms/step - loss: 4.8431e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3959 - val_sparse_categorical_accuracy: 0.7438\n",
      "Epoch 37/75\n",
      "122/122 [==============================] - 103s 848ms/step - loss: 4.6848e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4049 - val_sparse_categorical_accuracy: 0.7437\n",
      "Epoch 38/75\n",
      "122/122 [==============================] - 104s 850ms/step - loss: 4.5305e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4097 - val_sparse_categorical_accuracy: 0.7437\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fit model 3992.4630388369987\n",
      " 2/11 [====>.........................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_predict_batch_end` time: 0.1980s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_predict_batch_end` time: 0.1980s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 208ms/step\n",
      "Prediction Accuracy: 0.9111328125\n",
      "[[1612    0    0    0]\n",
      " [   0 2281    3  100]\n",
      " [   0   68 2262   54]\n",
      " [   0  687   81 4002]] \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      1612\n",
      "           1      0.751     0.957     0.842      2384\n",
      "           2      0.964     0.949     0.956      2384\n",
      "           3      0.963     0.839     0.897      4770\n",
      "\n",
      "    accuracy                          0.911     11150\n",
      "   macro avg      0.920     0.936     0.924     11150\n",
      "weighted avg      0.923     0.911     0.913     11150\n",
      " \n",
      "\n",
      "\n",
      "Total Time 3998.419894826002\n",
      "Model Number 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bd3c1a75a6cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                         \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                         \u001b[0mVal_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                                         \u001b[0mpredict_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                                         \u001b[0mfilt_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0mkernel_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_y' is not defined"
     ]
    }
   ],
   "source": [
    "append_list_time1=pd.DataFrame()\n",
    "Learning_Rate = 0.02\n",
    "Drop_rate = 0\n",
    "Repeats = 75\n",
    "m_count=0\n",
    "tf.keras.backend.clear_session()\n",
    "Drop_rate=0\n",
    "m_count += 1\n",
    "print('Model Number %s' % m_count)\n",
    "model2, history2, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=8,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "Drop_rate=0.1\n",
    "m_count += 1\n",
    "print('Model Number %s' % m_count)\n",
    "model2, history2, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=8,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_length = 8192\n",
    "target = 'label'\n",
    "cwd = os.getcwd()\n",
    "col_ran = [*range(8192)]\n",
    "d_t = dict()\n",
    "d_t['label'] = 'int8'\n",
    "d_t['Unnamed: 0'] = 'int8'\n",
    "for col in col_ran:\n",
    "    d_t['%s' % col] =  'float16'\n",
    "\n",
    "\n",
    "\n",
    "train_frame = pd.read_csv((r'{}.csv').format('train_df_w48_8192'), dtype=(d_t))\n",
    "test_frame = pd.read_csv((r'{}.csv').format('test_df_w48_8192'), dtype=(d_t))\n",
    "\n",
    "train_frame = train_frame.set_index(train_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "train_target = train_frame.pop('label')\n",
    "train_x = train_frame.to_numpy().reshape(len(train_frame), segment_length, 1)\n",
    "train_y = train_target.to_numpy().reshape(-1, 1)\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(b_size).with_options(options).cache()\n",
    "test_frame = test_frame.set_index(test_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "test_target = test_frame.pop('label')\n",
    "test_x = test_frame.to_numpy().reshape(len(test_frame), segment_length, 1)\n",
    "test_y = test_target.to_numpy().reshape(-1, 1)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(b_size).with_options(options).cache()\n",
    "print('class balance of train frame: %s' % train_target.value_counts())\n",
    "print('class balance of validation (test) frame: %s' % test_target.value_counts())\n",
    "out_1 = train_dataset\n",
    "out_2 = test_dataset\n",
    "\n",
    "val_frame = pd.read_csv((r'{}.csv').format('pred_df_no48_8192'), dtype=d_t)\n",
    "\n",
    "\n",
    "val_frame = val_frame.set_index(val_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "val_target = val_frame.pop('label')\n",
    "print('class balance of train frame: %s' % val_target.value_counts())\n",
    "val_x = val_frame.to_numpy().reshape(len(val_frame), segment_length, 1)\n",
    "val_y = val_target.to_numpy().reshape(-1, 1)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(b_size).with_options(options).cache()\n",
    "\n",
    "val_dataset = dataset\n",
    "predict_labels = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "Drop_rate=0\n",
    "m_count += 1\n",
    "print('Model Number %s' % m_count)\n",
    "model1, history1, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=8,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "Drop_rate=0.1\n",
    "m_count += 1\n",
    "print('Model Number %s' % m_count)\n",
    "model1, history1, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=8,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = 8192\n",
    "target = 'label'\n",
    "cwd = os.getcwd()\n",
    "col_ran = [*range(8192)]\n",
    "d_t = dict()\n",
    "d_t['label'] = 'float32'\n",
    "d_t['Unnamed: 0'] = 'float32'\n",
    "for col in col_ran:\n",
    "    d_t['%s' % col] =  'float32'\n",
    "\n",
    "\n",
    "\n",
    "train_frame = pd.read_csv((r'{}.csv').format('train_df_w48_8192'), dtype=(d_t))\n",
    "test_frame = pd.read_csv((r'{}.csv').format('test_df_w48_8192'), dtype=(d_t))\n",
    "\n",
    "train_frame = train_frame.set_index(train_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "train_target = train_frame.pop('label')\n",
    "train_x = train_frame.to_numpy().reshape(len(train_frame), segment_length, 1)\n",
    "train_y = train_target.to_numpy().reshape(-1, 1)\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(b_size).with_options(options).cache()\n",
    "test_frame = test_frame.set_index(test_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "test_target = test_frame.pop('label')\n",
    "test_x = test_frame.to_numpy().reshape(len(test_frame), segment_length, 1)\n",
    "test_y = test_target.to_numpy().reshape(-1, 1)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(b_size).with_options(options).cache()\n",
    "print('class balance of train frame: %s' % train_target.value_counts())\n",
    "print('class balance of validation (test) frame: %s' % test_target.value_counts())\n",
    "out_1 = train_dataset\n",
    "out_2 = test_dataset\n",
    "\n",
    "val_frame = pd.read_csv((r'{}.csv').format('pred_df_no48_8192'), dtype=d_t)\n",
    "\n",
    "\n",
    "val_frame = val_frame.set_index(val_frame.iloc[:, 0]).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "val_target = val_frame.pop('label')\n",
    "print('class balance of train frame: %s' % val_target.value_counts())\n",
    "val_x = val_frame.to_numpy().reshape(len(val_frame), segment_length, 1)\n",
    "val_y = val_target.to_numpy().reshape(-1, 1)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_optimization.apply_default_optimizations = True\n",
    "dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y)).batch(b_size).with_options(options).cache()\n",
    "\n",
    "val_dataset = dataset\n",
    "out_2 = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()\n",
    "Drop_rate=0\n",
    "m_count += 1\n",
    "print('Model Number %s' % m_count)\n",
    "model1, history1, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=8,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "Drop_rate=0.1\n",
    "m_count += 1\n",
    "print('Model Number %s' % m_count)\n",
    "model1, history1, y_preds, res_list = train_func2(train_data=train_dataset,\n",
    "                                        test_dataset=test_dataset,\n",
    "                                        Val_dataset=val_dataset,\n",
    "                                        predict_labels=predict_labels, \n",
    "                                        filt_num=8,\n",
    "                                        kernel_num=11,\n",
    "                                        dilation=7,\n",
    "                                        stack=1,\n",
    "                                        learn_r=Learning_Rate,\n",
    "                                        drop_rate=Drop_rate,\n",
    "                                        runs=Repeats,\n",
    "                                        Model_num = m_count, \n",
    "                                        segment_length = segment_length,\n",
    "                                        callback = callback)\n",
    "\n",
    "append_list_time1 = append_list_time1.append(res_list, ignore_index=True)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
